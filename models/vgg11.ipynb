{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg11.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MbtUcKfE_I4g"
      },
      "source": [
        "**Installs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tzg4cO9xLvUG",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "!pip3 install 'torch==1.3.1'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fxs_3zcG_NZd"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C7N0hU-VLx8W",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import vgg11\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "#NUM_CLASSES = 102\n",
        "NUM_CLASSES = 6\n",
        "DEVICE = 'cuda'\n",
        "MOMENTUM = 0.9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uvABcepY_Vfe"
      },
      "source": [
        "**Model definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vztVCv3fQXjR",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "def get_datasets(train_data_dir, test_data_dir, compose=[transforms.Resize(224),\n",
        "                                                         transforms.CenterCrop(224),\n",
        "                                                         transforms.ToTensor()\n",
        "                                                         ]):\n",
        "    train_transform = transforms.Compose(compose)\n",
        "    eval_transform = transforms.Compose([\n",
        "          transforms.Resize(224),\n",
        "          transforms.CenterCrop(224),\n",
        "          transforms.ToTensor()#,\n",
        "          #transforms.Normalize((45.6068733, 0.81077038, 57.85301916), (66.92374056, 9.88349788, 49.96761776))\n",
        "          ])\n",
        "\n",
        "    '''\n",
        "    if not os.path.isdir('./Homework2-Caltech101'):\n",
        "        !git clone https://github.com/MachineLearning2020/Homework2-Caltech101.git\n",
        "\n",
        "    '''\n",
        "    if not os.path.isdir('./AIML_project'):\n",
        "        !git clone https://github.com/anphetamina/AIML_project.git\n",
        "    \n",
        "    train_dataset = torchvision.datasets.ImageFolder(train_data_dir, transform=train_transform)\n",
        "    test_dataset = torchvision.datasets.ImageFolder(test_data_dir, transform=eval_transform)\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "def test_network(net, test_dataset, batch_size):\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "    net.train(False)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    sum_test_losses = 0.0\n",
        "    running_corrects = 0\n",
        "    for images, labels in test_dataloader:\n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      # Forward Pass\n",
        "      outputs = net(images)\n",
        "\n",
        "      # Get predictions\n",
        "      _, preds = torch.max(outputs.data, 1)\n",
        "      test_loss = criterion(outputs, labels)\n",
        "      sum_test_losses += test_loss.item()*images.size(0)\n",
        "\n",
        "      # Update Corrects\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    accuracy = running_corrects / float(len(test_dataset))\n",
        "\n",
        "    # Calculate loss\n",
        "    test_loss = sum_test_losses / float(len(test_dataset))\n",
        "\n",
        "    return accuracy, test_loss\n",
        "\n",
        "def train_network(net, parameters_to_optimize, learning_rate, num_epochs, batch_size, weight_decay, step_size, gamma, train_dataset, val_dataset=None, verbosity=False, plot=False):\n",
        "  \n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=False)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(parameters_to_optimize, lr=learning_rate, momentum=MOMENTUM, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "    net = net.to(DEVICE)\n",
        "    best_net = vgg11()\n",
        "    best_net = best_net.to(DEVICE)\n",
        "    best_net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "\n",
        "    cudnn.benchmark\n",
        "\n",
        "    train_accuracies = []\n",
        "    train_losses = []\n",
        "    val_accuracies = []\n",
        "    val_losses = []\n",
        "\n",
        "    current_step = 0\n",
        "    best_val_accuracy = 0.0\n",
        "    best_val_loss = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        train_running_corrects = 0\n",
        "        sum_train_losses = 0.0\n",
        "\n",
        "        for images, labels in train_dataloader:\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            net.train()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = net(images)\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            train_running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "            loss = criterion(outputs, labels)\n",
        "            sum_train_losses += loss.item()*images.size(0)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            current_step += 1\n",
        "        \n",
        "        if val_dataset is not None:\n",
        "            val_accuracy, val_loss = test_network(net, val_dataset, batch_size)\n",
        "            if val_accuracy > best_val_accuracy:\n",
        "                best_val_accuracy = val_accuracy\n",
        "                best_val_loss = val_loss\n",
        "                best_net.load_state_dict(net.state_dict())\n",
        "            val_accuracies.append(val_accuracy)\n",
        "            val_losses.append(val_loss)\n",
        "\n",
        "        # Calculate accuracy on train set\n",
        "        train_accuracy = train_running_corrects / float(len(train_dataset))\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        # Calculate loss on training set\n",
        "        train_loss = sum_train_losses/float(len(train_dataset))\n",
        "        train_losses.append(loss)\n",
        "\n",
        "        if verbosity:\n",
        "            if val_dataset is not None:\n",
        "                print(\"train_acc: {}, val_acc: {}, train_loss: {}, val_loss: {} ({} / {})\".format(train_accuracy, val_accuracy, train_loss, val_loss, epoch+1, num_epochs))\n",
        "            else:\n",
        "                print(\"train_acc: {}, train_loss: {} ({} / {})\".format(train_accuracy, train_loss, epoch+1, num_epochs))\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    if plot:\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        line1, = ax.plot(train_losses, label='Loss on training set')\n",
        "        line2, = ax.plot(train_accuracies, label='Accuracy on training set')\n",
        "        ax.legend()\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.show()\n",
        "\n",
        "        if val_dataset is not None:\n",
        "            fig, ax = plt.subplots()\n",
        "            line1, = ax.plot(val_accuracies, label='Accuracy on validation set', color='C2')\n",
        "            line2, = ax.plot(train_accuracies, label='Accuracy on training set', color='C3')\n",
        "            ax.legend()\n",
        "            plt.xlabel(\"Epochs\")\n",
        "            plt.show()\n",
        "        \n",
        "            fig, ax = plt.subplots()\n",
        "            line1, = ax.plot(val_losses, label='Loss on validation set', color='C1')\n",
        "            line2, = ax.plot(train_losses, label='Loss on training set', color='C7')\n",
        "            ax.legend()\n",
        "            plt.xlabel(\"Epochs\")\n",
        "            plt.show()\n",
        "\n",
        "    \n",
        "    return best_net, best_val_accuracy, best_val_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I6fTm2sD_BOt"
      },
      "source": [
        "**Train + validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XtBXC1cO_A6A",
        "outputId": "a3fa770c-5f78-4eed-dede-86a12a22396b",
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# lr 0.0042237987628595194, batch 15, decay 0.00042683917479004744, gamma 0.031192333743237592, val accuracy 0.4975369458128079, val loss 1.1257490495155598 [4 / 50]\n",
        "BATCH_SIZE = 8\n",
        "LR = 0.0005\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 0\n",
        "NUM_EPOCHS = 15\n",
        "STEP_SIZE = 9\n",
        "GAMMA = 1\n",
        "\n",
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-672'\n",
        "#TRAIN_DATA_DIR = 'Homework2-Caltech101/101_ObjectCategories'\n",
        "compose=[transforms.Resize(224),\n",
        "         transforms.CenterCrop(224),\n",
        "         transforms.RandomGrayscale(),\n",
        "         transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
        "         transforms.ToTensor()\n",
        "         ]\n",
        "train_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\n",
        "train_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]\n",
        "val_indexes = [idx for idx in range(len(train_dataset)) if not idx % 5]\n",
        "val_dataset = Subset(val_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "print('training set {}'.format(len(train_dataset)))\n",
        "print('validation set {}'.format(len(val_dataset)))\n",
        "\n",
        "net = vgg11()\n",
        "net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "best_net, val_accuracy, val_loss = train_network(net, net.parameters(), LR, NUM_EPOCHS, BATCH_SIZE, WEIGHT_DECAY, STEP_SIZE, GAMMA, train_dataset, val_dataset=val_dataset, verbosity=True, plot=True)\n",
        "\n",
        "print('val accuracy {}'.format(val_accuracy))\n",
        "print('val loss {}'.format(val_loss))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set 809\n",
            "validation set 203\n",
            "train_acc: 0.1668726823238566, val_acc: 0.2512315270935961, train_loss: 1.7879389786749746, val_loss: 1.773600395677125 (1 / 15)\n",
            "train_acc: 0.20148331273176762, val_acc: 0.18226600985221675, train_loss: 1.763437539302227, val_loss: 1.7515796417085996 (2 / 15)\n",
            "train_acc: 0.1915945611866502, val_acc: 0.24630541871921183, train_loss: 1.7541084682985644, val_loss: 1.7281330724067876 (3 / 15)\n",
            "train_acc: 0.21631644004944375, val_acc: 0.21182266009852216, train_loss: 1.7098876542891797, val_loss: 1.6824277510196703 (4 / 15)\n",
            "train_acc: 0.27070457354758964, val_acc: 0.2857142857142857, train_loss: 1.6684635008221356, val_loss: 1.6383854250602534 (5 / 15)\n",
            "train_acc: 0.311495673671199, val_acc: 0.30049261083743845, train_loss: 1.6174655830020221, val_loss: 1.5798739923044967 (6 / 15)\n",
            "train_acc: 0.3374536464771323, val_acc: 0.27586206896551724, train_loss: 1.5829884606621911, val_loss: 1.6170514493153012 (7 / 15)\n",
            "train_acc: 0.33868974042027195, val_acc: 0.35960591133004927, train_loss: 1.565777651753797, val_loss: 1.540208471232447 (8 / 15)\n",
            "train_acc: 0.37453646477132263, val_acc: 0.37438423645320196, train_loss: 1.538555459127438, val_loss: 1.5235949766459724 (9 / 15)\n",
            "train_acc: 0.3819530284301607, val_acc: 0.27586206896551724, train_loss: 1.5283125356042342, val_loss: 1.669509948768052 (10 / 15)\n",
            "train_acc: 0.36711990111248455, val_acc: 0.3694581280788177, train_loss: 1.517299587263902, val_loss: 1.5037719304925703 (11 / 15)\n",
            "train_acc: 0.3794808405438813, val_acc: 0.3645320197044335, train_loss: 1.4933163727759136, val_loss: 1.484985688049805 (12 / 15)\n",
            "train_acc: 0.38813349814585907, val_acc: 0.3645320197044335, train_loss: 1.4622084659757957, val_loss: 1.4649977830830465 (13 / 15)\n",
            "train_acc: 0.37824474660074164, val_acc: 0.41379310344827586, train_loss: 1.4905931339570413, val_loss: 1.418855686493108 (14 / 15)\n",
            "train_acc: 0.40914709517923364, val_acc: 0.41379310344827586, train_loss: 1.4284443794870554, val_loss: 1.4552194073869678 (15 / 15)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEGCAYAAABrQF4qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJPqIiJZLoo+IaLl/Ab6f7jvTWJafAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEGCAYAAABrQF4qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdeVxVRf/A8c9w2RcBAUVAccNcUFBJ\nE9yXUlNMzbLV6sm0xdR6TEuztOVXuWT76vJkipaWopkFueEuqKXiigICKvu+3cud3x8goYIgXPZ5\nv16+5J5zZuZ7Fb7MnTNnRkgpURRFURouo9oOQFEURaleKtEriqI0cCrRK4qiNHAq0SuKojRwKtEr\niqI0cMa1HcDNHB0dZevWrWs7DEVRlHolLCwsUUrpVNq5OpfoW7duTWhoaG2HoSiKUq8IIaLKOqeG\nbhRFURo4legVRVEaOJXoFUVRGrg6N0ZfGq1WS0xMDLm5ubUdiqLcwtzcHDc3N0xMTGo7FEUpVb1I\n9DExMdjY2NC6dWuEELUdjqIUk1KSlJRETEwMbdq0qe1wFKVU9WLoJjc3FwcHB5XklTpHCIGDg4P6\ntKnUafUi0QMqySt1lvreVOq6ejF0oyiKUlck5iSy8dxGtHqtwetubtWcCR0mGLxelejvwKZNmxg7\ndiynT5+mY8eOtR1Onfb2229jbW3Nf//7X+bPn0///v0ZOnToDdfs2rWLxYsXs3Xr1jLrOX78OHFx\ncYwcORKAwMBAwsPDmTNnTrXGf7NVq1Zx77334uLiUqPtKnXPm/veZG/sXgSG/yTX1amrSvS1LSAg\ngL59+xIQEMCCBQuqrZ2CggI0Gk211V/TFi5cWOmyx48fJzQ0tDjR+/v74+/vb6jQKmzVqlV4enqq\nRN/IHbxykL2xe3m156s85flUbYdTYfVmjL62ZWZmsnfvXpYvX866detuOPfhhx/StWtXvLy8inua\nFy5cYOjQoXh5edGjRw8iIiLYtWsXo0aNKi730ksvsWrVKqBw6YfZs2fTo0cPfv75Z7777jvuvvtu\nvLy8GD9+PNnZ2QBcu3aNsWPH4uXlhZeXF/v372f+/PksW7asuN65c+fyySef3PIeli5diqenJ56e\nnsXXR0ZG0qlTJyZPnkyXLl249957ycnJuaFcWloa7u7u6PV6ALKysmjZsiVarbbMOEt66qmn2LBh\nAwDbt2+nY8eO9OjRg19++aX4msOHD9OnTx+6d++Or68vZ8+eJT8/n/nz57N+/Xq8vb1Zv349q1at\n4qWXXiqOffDgwXTr1o0hQ4YQHR1d3N7LL7+Mr68vbdu2LW67pKysLO6//368vLzw9PRk/fr1AISF\nhTFgwAB69uzJfffdx5UrV9iwYQOhoaE89thjeHt73/LvozQOeqlnaehSXKxceKTTIwavX+r1VNeO\nf/WuR//h4Q85k3zGoHV2bNqR2b1m3/aazZs3M3z4cDp06ICDgwNhYWH07NmT33//nc2bN3Po0CEs\nLS1JTk4G4LHHHmPOnDmMHTuW3Nxc9Ho9ly9fvm0bDg4OHD16FICkpCQmT54MwLx581i+fDnTpk3j\n5ZdfZsCAAfz6668UFBSQmZmJi4sL48aNY8aMGej1etatW8fhw4dvqDssLIyVK1dy6NAhpJT07t2b\nAQMGYG9vz/nz5wkICOC7777joYceYuPGjTz++OPFZW1tbfH29mb37t0MGjSIrVu3ct9992FiYsK4\nceNKjbM0ubm5TJ48mR07dtC+fXsefvjhf/8POnYkJCQEY2NjgoODeeONN9i4cSMLFy4kNDSUzz//\nHKD4FyPAtGnTmDRpEpMmTWLFihW8/PLLbNq0CYArV66wd+9ezpw5g7+/Pw8++OANsWzfvh0XFxd+\n++03oPCXmVarZdq0aWzevBknJyfWr1/P3LlzWbFiBZ9//jmLFy/Gx8fntv+HSsP128XfOJ18mg/6\nfYCZxszg9V/74AP06Rm0eO9dhIE/0asefQUFBAQwceJEACZOnEhAQAAAwcHBPP3001haWgLQtGlT\nMjIyiI2NZezYsUDhAzXXz99OycR38uRJ+vXrR9euXVmzZg2nTp0CYMeOHTz//PMAaDQabG1tad26\nNQ4ODhw7dow///yT7t274+DgcEPde/fuZezYsVhZWWFtbc24ceMICQkBoE2bNnh7ewPQs2dPIiMj\nS43teq933bp1xbGWFWdpzpw5Q5s2bfDw8EAIccMvk7S0NCZMmICnpyczZ868bT3XHThwgEcffRSA\nJ554gr179xafe+CBBzAyMqJz585cu3btlrJdu3YlKCiI2bNnExISgq2tLWfPnuXkyZMMGzYMb29v\n3n33XWJiYsqNQ2n4cnW5fHrsUzo7dGZEmxEGrz9p1SpSfliNxraJwZM81MMefXk97+qQnJzMjh07\nOHHiBEIICgoKEEKwaNGiO6rH2Ni4ePgDuGXutZWVVfHXTz31FJs2bcLLy4tVq1axa9eu29b97LPP\nsmrVKq5evcozzzxzR3GZmf3bO9FoNKUOTfj7+/PGG2+QnJxMWFgYgwcPrlScZXnzzTcZNGgQv/76\nK5GRkQwcOLBS9VxX8j2V9nG4Q4cOHD16lG3btjFv3jyGDBnC2LFj6dKlCwcOHKhS20rD8+PpH7ma\ndZX3+76PkTBs/zh9+x/Ef/gRNvfeS7PZ1ZPfVI++AjZs2MATTzxBVFQUkZGRXL58mTZt2hASEsKw\nYcNYuXJl8dh0cnIyNjY2uLm5FQ8j5OXlkZ2djbu7O+Hh4eTl5ZGamspff/1VZpsZGRm0aNECrVbL\nmjVrio8PGTKEr776Cii8aZuWlgbA2LFj2b59O0eOHOG+++67pb5+/fqxadMmsrOzycrK4tdff6Vf\nv34V/jewtrbm7rvvZvr06YwaNar4ZnFZcZamY8eOREZGEhERAVD8qQgKe/Surq7AjcMzNjY2ZGRk\nlFqfr69v8f2SNWvW3NH7iYuLw9LSkscff5xZs2Zx9OhR7rrrLhISEooTvVarLf5kcbs4lIYtOTeZ\n5SeWM8BtAHc7323QurPDwoh77TUsvL1x+ehDhFH1pGSV6CsgICCgeBjmuvHjxxMQEMDw4cPx9/fH\nx8cHb29vFi9eDMDq1av59NNP6datG76+vly9epWWLVvy0EMP4enpyUMPPUT37t3LbPOdd96hd+/e\n+Pn53TCV85NPPmHnzp107dqVnj17Eh4eDoCpqSmDBg3ioYceKnXGTo8ePXjqqafo1asXvXv35tln\nn71t+6V5+OGH+fHHH28YYiorztKYm5vz7bffcv/999OjRw+aNWtWfO61117j9ddfp3v37uh0uuLj\ngwYNIjw8vPhmbEmfffYZK1eupFu3bqxevbrUG9BlOXHiBL169cLb25sFCxYwb948TE1N2bBhA7Nn\nz8bLywtvb2/2798PFH5ymTp1qroZ2wh98/c3ZOuymdlzpkHrzbt4iZgXXsTExQW3L7/AyNzcoPXf\nQEpZ7h9gOHAWuADMuc114wEJ+JQ49npRubPAfeW11bNnT3mz8PDwW44pNyooKJBeXl7y3LlztR1K\no6S+RxumyLRI6f0/b7lg/wKD1qtNSJDnhwyVZ339ZF50tEHqBEJlGXm13B69EEIDfAGMADoDjwgh\nOpdynQ0wHThU4lhnYCLQpeiXxZdF9SkGFB4eTvv27RkyZAgeHh61HY6iNBifHP0EE40JL3i/YLA6\n9dnZXJ76PLqkJFp+/RWmLVsarO6yVORmbC/ggpTyIoAQYh0wBgi/6bp3gA+BWSWOjQHWSSnzgEtC\niAtF9am7XQbUuXNnLl68WNthKEqDcjz+OEFRQbzg/QKOFo4GqVPqdMTOfIXc8HDcvvgci65dDVJv\neSoyRu8KlJwAHlN0rJgQogfQUkr5252WLSr/nBAiVAgRmpCQUKHAFUVRqouUksWhi3GycGJS50kG\nq/PqO++SuXs3zvPfxGbQIIPUWxFVvhkrhDAClgKvVrYOKeW3UkofKaWPk1Opm5griqLUmODoYP5O\n+JsXvV/E0qT8Z2AqIunb70hdvx6HyZOxL3omp6ZUZOgmFig5iORWdOw6G8AT2FW0XKszECiE8K9A\nWUVRlDpFW6BlWdgy2tu154H2DxikzrQtW0j4+GOajBqF08wZBqnzTlSkR38E8BBCtBFCmFJ4czXw\n+kkpZZqU0lFK2VpK2Ro4CPhLKUOLrpsohDATQrQBPIDDtzahKIpSN/x07ieiM6KZ2XMmGqOqzx3J\nOniQuDfmYtmrFy3ef6/a5srfTrktSil1wEvAH8Bp4Ccp5SkhxMKiXvvtyp4CfqLwxu124EUpZUHV\nw64dmzZtQgjBmTOGXWunPti0aVPxnP07ERgYyAcffHDba+Li4m5Zi6YmpKam8uWXX9Z4u0rdlZ6f\nztd/f01v5970c634A3hlyT13jpiXpmHW2h23zz/DyNTUAFHeuQr9apFSbpNSdpBStpNSvld0bL6U\nMrCUawcW9eavv36vqNxdUsrfDRd6zSu5THF1Kiioe78Lb5foSz7gdDN/f/9y1453cXEpdYXJ6qYS\nvXKz5SeWk5aXxqs+r1Z55zDttWtcfm4KRpaWtPzmGzRNmhgoyjunnoytoMa8TPH+/fsJDAxk1qxZ\neHt7ExERwcCBA5kxYwY+Pj588sknbNmyhd69e9O9e3eGDh1avJBYyWWFy1o+ODIyEk9Pz+Lrx40b\nx/Dhw/Hw8OC1114rjmP58uV06NCBXr16MXny5OJ6S9q9ezfe3t54e3vTvXv34mULFi1axN133023\nbt146623AJgzZw4RERF4e3sza9asW+pSGpcrmVf4MfxHRrUdRSeHTlWqqyAzk8vPTUGfnk7Lb77G\npJb3Mah3i5pdff998k4bdujErFNHnN9447bXNOZlin19ffH392fUqFE3DLHk5+cTGlr44S0lJYWD\nBw8ihOD777/no48+YsmSJbe8x/KWD4bCzUaOHTuGmZkZd911F9OmTUOj0fDOO+9w9OhRbGxsGDx4\nMF5eXreUXbx4MV988QV+fn5kZmZibm7On3/+yfnz5zl8+DBSSvz9/dmzZw8ffPABJ0+e5Pjx47f9\nf1Eah8+OfQbAtO6lL7NdUVKrJfbl6eRFRNDy668x71S1XxqGUO8SfW0JCAhg+vTpwL/LFPfs2bPC\nyxRXxM3LFM+bN4/U1FQyMzOLFyrbsWMHP/zwA/DvMsW2trbFyxRfu3at3GWKgeJliv39/Su0THF5\n8cbExPDwww9z5coV8vPzadOmTallyls+GAoXbrO1tQUKHwaLiooiMTGRAQMG0LRpUwAmTJjAuXPn\nbinr5+fHK6+8wmOPPca4ceNwc3Pjzz//LF6+GQo/nZ0/f55WrVpV6H0qDd/ppNNsvbiVpz2fpoV1\ni0rXI6Xkypvzydq/nxbvv491Xz8DRll59S7Rl9fzrg5qmeLSlYx32rRpvPLKK/j7+7Nr1y7efvvt\nctuSZeymc3M8t7sHcLM5c+Zw//33s23bNvz8/Pjjjz+QUvL6668zZcqUG66t6C80pX4pyMggc9du\nMoKCyD52FMsePbEd4491376IUm6GSilZErYEWzNbnu36bJXaTvzsc9I2bcLxpZewGze2/AI1RI3R\nV4Baprj8ZXpLLjP8v//9r8L1VtTdd9/N7t27SUlJQafTsXHjxlKvi4iIoGvXrsyePZu7776bM2fO\ncN9997FixQoyMzMBiI2NJT4+Xi093IDoEhNJ+eknoic/xzlfP+JmzSpM8j19yD5yhJgXXuR8/wFc\nXfgOOf/8c0MnY2/sXg5dOcRUr6nYmNpUOobUDRtI/PJLbMePw/FFw62NYwj1rkdfGwICAph904YA\n15cp/uqrrzh+/Dg+Pj6YmpoycuRI3n//fVavXs2UKVOYP38+JiYm/Pzzz7Rt27Z4meI2bdpUaJli\nJycnevfuXZyQPvnkE5577jmWL1+ORqPhq6++ok+fPsXLFNvZ2ZW7TDFQvExxRXu1EydOZPLkyXz6\n6aelzpB5++23mTBhAvb29gwePJhLly5VqN6KcnV15Y033qBXr140bdqUjh07Fg/vlLRs2TJ27tyJ\nkZERXbp0YcSIEZiZmXH69Gn69OkDFK6t/+OPP9KuXTv8/Pzw9PRkxIgRd/wJTald+TGxZAQHkREc\nTE7YUZASk5YtafrEE9gMHYqFtxfCyAip1ZK5bx/pgYGkbthAytq1mLZuje0Yf6xGjWTp0aW0smnF\nQx0eqnQsmSEhXHnrbaz69qXF229XecaOoYmyPj7XFh8fH3n9Bt91p0+fplMduKFRl+n1+uIZOw11\nBcvMzEysra3R6XSMHTuWZ5555pZ9AmqL+h6tflJK8i9cICM4mPSgIPLCTwNgdtdd2Awdis29wzDr\n0OG2SbYgI4OMP/4gbXMg2UeOABDeEpzHPcw9j71SqSmQueHhRD3+BCbu7rivXo3G2qr8QtVACBEm\npSx1U2PVo28AwsPDGTVqFGPHjm2wSR4KPzUEBweTm5vLvffeywMPGObxdKXuklKSe+IEGUFBZAQF\nk1/0CdTC25tms/6LzdChmLq7V7g+jY0Ndg8+iN2DD5IeeYGvFj2C7wktTT9Zz/mvfsV68GBs/f2x\n7tcXYWJSbn3a2Fiip0zByM6Wll9/XWtJvjwq0TcAjWWZ4uu7dyml0+fmkh0aRtb+/WTt24fu6lWa\nPjWJppMmYVSBzenrCqnTkR0aVpjc//oL3dWroNFg1bsXTSc9ifXgIZg0b1Z+ReVYkxbEj71yuW/+\nD7SONyZtcyDpv/1GxvbtaOztaTJyJLYPjMHc07PUTwkFaWlEPzcFmZuH+4oVBomputSbRC+lrHPj\nXooCZc8eqol2886dI2vvPrL27SM7NBSZn48wMcHCpycmzs4kfPIpKWsDcJz2EnbjxiGM6+aPvD4v\nj6x9+8kIDiZzxw4KUlMRZmZY9e2LzYzp2AwciMbOzmDtJeYksvLkSoa5D8O7eXdoDhZdu9J89mtk\n7t1L2uZAUn/+mZQ1azBt0wbbMf7Yjh6NSdGEA31+PjEvTUMbHU3L77/HrI5/kq4XY/SXLl3CxsYG\nBwcHleyVOkVKSVJSEhkZGWU+O2BIuoSEwh77/v1k7t9PQUIiAGYe7bHy9cOqrx+WPj4YWVgAkH30\nKPGLFpNz7Bim7drR7NVXsR40sM78HOkSEkhes4aUgHXo09IwsrbGetAgbIYOxbpf32r7JLLwwEJ+\nPf8rmx7YhHuT0od+CtLTSf/jD9I3B5JdlJMsfXxoMsaf7AMHSd+2DZfFi7EddX+1xHinbjdGXy8S\nvVarJSYm5pZ554pSF5ibm+Pm5oZJBcZ075Q+N5fssDCy9hUOx+SdPQuAxt4eK19frPz8sPLzxaR5\n8zLrkFKSERxMwpKl5EdGYunjQ7PXZmHRrZvB462ovIgIkletIm3TZqROh83Qodg9NAGr3r1Lnetu\nSBdTLzIucBwP3/Uwr/d+vUJl8mNiSd8SSNrmwOL7BE6vvoJj0dPrdUG9T/SK0lgUD8cUJfbs0FBk\nXl7hcEzPnlj5+WLl64t5p053vNyt1GpJ3bCBhM+/oCApCZsRw2k2cyamNfSEsJSSnNBQklasJHPn\nToSZGbbjxuIwaRKmrVvXSAwA0/6aRui1ULaN24a9uf0dlb1+c1gbG4vN8OF15pMRqESvKHWaLjGx\n+AZqyeEY0/btsPbzw8qvaDjGQMMYBZlZJK9cSdKKFUitFvuJE3F84XmMi5aXMDRZUEBGUBBJK1aS\n+88/aOztsX/sMewffaTa2izLkatHeOaPZ5jeY3qVn4Kta1SiV5Q6KEeXw5ZfPqTjwp8w0Uk0dnY3\nDsc4O1dr+9r4eBK/+JLUDRswMjfHYfJkmk56snh8v6r02dmk/vIryatWoY2JwcS9FQ5PP43tmDEG\na+OO4pF6HvntEZJzk9nywBbMjSu2BlV9oebRK0odUqAvYHPEZv6391Ne++IaCTZwfvoopjz0YY3u\nPmTSrBktFrxN0yefIH7pxyQsW0bK2rU4TX8Z2wceQJTyhHVF6BITSV6zhtS1ARSkpRXOeZ/9GjaD\nB1e6TkP4/dLvhCeF837f9xtcki+P6tErSg2RUrInZg/Lji4jIvk8//eLJW2iclkzsysn7TPZ/MDm\nWo0vOyyM+I8WkfP335h5tMfp1VexHjCgwuPQeRcvkrxyFWmbNyO1WqyHDMbhmf9g2aPspT5qSl5B\nHv6/+mNrZsu6UeswEg1vmS/Vo1eUWnYi4QRLwpYQdi0M9ybufBt3L7bnf6fFu+/QoVMWgaGLuZp1\nFWer6h2uuR3Lnj1xXxdAxp9BxC9dQszU57Hs1Ytms2Zh0dWz1DJSSnKOHiVp+Qoyd+xAmJpiO3Ys\nTZ+ahFkNTDetqIDTAcRlxbHAb0GDTPLlUYleUapRdHo0nxz9hD+j/qSpeVPm9p7LiERX4n6cgu2Y\nMdiOH49fagSLWcz+uP2M8xhXq/EKIWhy373YDB5Eyk8/kfjFl0ROmECTkSNxmjmDj6+sZdOFTXg0\nacfAS5Z4BV3C8lwMRna2OL7wAvaPPYrxTXsh1La0vDS+PfEtfV37ck+Le2o7nFqhEr2iVIOknCS+\n+ecbfj77MyYaE6Z6TeWpLk9hmpzFpWfGYtquLc5vzUcIQTu7djSzbMa+2H21nuivEyYmNH3sMWzH\njCFp+XKSV64i/c8/sexpzAPOtvTbdxL7xDyu2sHae43Y1S2T5k1/p8M/EXSw78Bd9nfRwb4Drjau\ntd6D/uafb8jSZvFKz1dqNY7apBK9ohhQtjab1eGrWXFyBXkFeYzzGMfzXs/jZOmE1OmIenUK+pwc\n3D/5oXi6pBACXxdfdkTvoEBfgMao9m5Y3kxjbU2z6dOxn/gIZxe9zeDfdmIkczH36kbTN5/B9p4u\niPQL3JVyjrPJZzmXco4d0TuQFN77szS2xMPe49/k37QDHnYeWJta10j8lzMuE3AmgAfaP4CHfd1e\npqA6qUSvKAag0+v49cKvfHX8KxJyEhjSagjTe0ynje2/49QJn3xKTmgYLh99iFm7djeU93XxZdOF\nTZxKOkU3p9p7YrUsJs2bsfOxTvzmtpfVA77D0bsXQghsARdbNwa2HFh8bY4uh4jUiOLEfzblLNsj\nt/PzuZ+Lr3G1di1O/B3sC//YmRluLZvrloUtw8TIhBe9XzR43fWJSvSKUgVSSnZe3smyo8u4lHYJ\nbydvlgxcQvdmN840ydi1i6TvvsNuwgRs/f1vqeeeFvcgEOyL21cnEz1ASEwIze/qjlP33re9zsLY\nAk9HTzwd/72BK6XkWva1G5L/uZRz7IrZhV7qb1Nb1U3pNoVmlnV3ZcmaoBK9olTS8fjjLA1byrH4\nY7Ru0pplg5YxuOXgW6YjamNjiZs9B7OOHWk+t/Q9j+3N7ens0JkDcQd43uv5mgj/jsRnx3M6+TTT\ne0yvVHkhBM5WzjhbOTOg5YDi4zm6HC6mXuRcyjmyddmGCreYtYk1I9uMNHi99Y1K9Ipyhy6lXeLT\no58SHB2Mo4Ujb97zJuM8xmFsdOuPk8zPJ+aVV0Cnw23ZxxiZl/2gjq+LLytOriAjP6NKe5dWh32x\n+wDo79bfoPVaGFvQxbELXRy7GLRe5UYq0StKBSXmJPL131+z4dwGzDRmvOD9ApM6T8LSpOw1aOKX\nLCH3739wXfZxuQt3+bn68d2J7zh85TBD3IcYOPqq2ROzh+aWzfGwa7w3NOszlegVpQL0Us+k3ycR\nlxnHhA4TmOI1BUcLx9uWSf/zT5L/9wP2jz9Ok+HDy22jm1M3rEys2Be3r04lem2BlgNXDjCizYg6\ntVqjUnEq0StKBfyT8A/RGdG86/cuY9qPKff6/Ohorsydh3nXrjR7bVaF2jAxMqGXcy/2x+2vUzuq\nHYs/RpY2i/6uhh22UWpO43sWWFEqISgqCGMjYwa3Glzutfq8PGJnzAQhcP34Y4zuYCMNXxdfYjNj\nic6Irkq4BhUSG4KJkQm9W9x+to1Sd6lEryjlkFISHBVMnxZ9KnST9NoHH5AbHo7LB/+HqZvrHbXl\n5+IH/Hvzsy7YE7MHn+Y+t70XodRtKtErSjnCk8OJy4pjmPuwcq9N2/obqQHraPqfZ7AZXH7v/2Yt\nm7TEzdqNA3EHKhOqwcVkxHAx7SL93PrVdihKFVQo0QshhgshzgohLggh5pRyfqoQ4oQQ4rgQYq8Q\nonPR8dZCiJyi48eFEF8b+g0oSnULjgpGIzQMajnottflXbzIlfnzsejRg2YzZlS6PT9XPw5fPYy2\nQFvpOgxlb+xewPDTKpWaVW6iF0JogC+AEUBn4JHribyEtVLKrlJKb+AjYGmJcxFSSu+iP1MNFbii\n1ITrwzY+zj7YmZf9iL4+J4fY6TMwMjPDdekSRBU2Cvd18SVbl83xhOOVrsNQ9sTsoZVNK9ybuNd2\nKEoVVKRH3wu4IKW8KKXMB9YBN0w7kFKml3hpBdSt3UwUpZIupF4gMj2SYa1uP2xz9Z13ybtwAZdF\ni6q8BWAv514YC2P2x+2vUj1VlavL5fDVw2rYpgGoSKJ3BS6XeB1TdOwGQogXhRARFPboXy5xqo0Q\n4pgQYrcQotTvGCHEc0KIUCFEaEJCwh2EryjVKzgqGIG47bz21I2/kPbLLzg+PxXrvn5VbtPa1Jpu\nTt1qPdEfuXqEvII8+rmqRF/fGexmrJTyCyllO2A2MK/o8BWglZSyO/AKsFYI0aSUst9KKX2klD5O\nTk6GCklRqiwoOojuzbqX+XBU7tlzXH3nHSx798bxRcOtkOjr4svppNMk5yYbrM47FRIbgoWxBT7O\npe5Op9QjFUn0sUDLEq/dio6VZR3wAICUMk9KmVT0dRgQAXSoXKiKUrOi0qM4n3Keoe5DSz1fkJlF\n7IwZGNlY47p4kUE3vvZz9UMia232zfX9bXs798ZMY1YrMSiGU5FEfwTwEEK0EUKYAhOBwJIXCCFK\nLoBxP3C+6LhT0c1chBBtAQ/goiECV5TqFhQVBMDQVrcmeiklV+fPJz8qCtfFSzA28CfRTk07YWtm\nW2vDN5fSLxGbGavG5xuIcpdAkFLqhBAvAX8AGmCFlPKUEGIhECqlDAReEkIMBbRACjCpqHh/YKEQ\nQgvogalSytr7LKoodyA4KuoUIuwAACAASURBVBhPB09aWLe45Vzq+vWkb9uG04wZWPXuZfC2NUYa\n+rTow4G4A7WyHEJITAiAGp9vICq01o2Uchuw7aZj80t8Xeoi1VLKjcDGqgSoKLUhLjOOU0mnmNHj\n1vnwOadOce2997Hq1w+H5yZXWwy+Lr5sj9zO+dTzdLCv2RHPkJgQ2tu1L/WXnFL/qCdjFaUUwVHB\nALc8DVuQnk7sjJloHBxw+ehDhFH1/Qj1cekDwP7Ymh2+yczPJCw+TA3bNCAq0StKKYKjg+lg34FW\nTVoVH5NScmXuXLRXruC6dCnG9vbVGoOzlTPt7drX+Dj9oSuH0Ol1atimAVHLFCtKEVlQgD4nl8Sk\naK6eOcYTbSeQHRaGPjsbfXYOOceOkREUTLPXXsOyR/fyKzSAPi59WH9mPTm6HCyMLWqkzZDYEGxM\nbPBu5l0j7SnVTyV6pcHJv3yZrL17CxN0Vnbh3zk5RQk7G5lT4niJczI3t7iOTwAIIIqAG+q2ufde\nmj79VI29Fz8XP1aHr+botaP4uVb9YazySCkJiQmhj0sfTIwqv4yDUreoRK80KDknThL97LPo09KK\njwlLS4wsLTGysCj829ISIysrjJs5YWRpibCwwMjSqviaNZEbSRRZ/LfvXIysLP8tY2mJiZtbjc6A\n6dG8B6ZGpuyL21cjif5sylnic+LV+HwDoxK90mBkh4Vx+bkpaOzscP/hB0xbuiHMze/ohmlKbgor\nfvqUZzyfoUmP8pclrm4Wxhb0bN6z8Ibs3dXf3vVplX1d+1Z/Y0qNUTdjlQYha/9+op+djLGTE+5r\nfsT8rg6FvfU7nBWz8/JOCmRBmU/D1gY/Vz8i0iK4mnW12tvaE7OHLg5dyt0PV6lfVKJX6r2MHTu5\nPPV5TFu2xP3H1VVaPTIoKghXa1c6Ne1kwAir5vo0y+peDiE1N5V/Ev9RwzYNkEr0Sr2W/vvvxLz8\nMmZ33YX7D//D2LHyPdH0/HQOXjnI0FZD68zG3AAedh44WThV+zTL/XH70Uu9mlbZAKlEr9Rbqb9u\nIvbV/2Lh5UWrlSvQ2JW9MUhF7L68G51eV6eGbQCEEPRx6cOBKwco0BdUWzshsSE0NW+Kp6NntbWh\n1A6V6JV6KXntWq68/jpW99xDq+++RWNtXeU6g6KCaGbRjG5O3QwQoWH5ufiRlpfG6eTT1VJ/gb6A\nvbF78XPxw0iotNDQqP9Rpd5JWr6CawvfwXrQINy++hIjS8sq15mtzWZ/3H6GuA+pk4nuHpd7EAj2\nxe6rlvpPJp0kNS9Vjc83UHXvO1pRyiClJOGzz4lftIgmI0fg9uknGJkZZq30PbF7yCvIu2Vtm7qi\nqXlTOjl0qrZx+pCYEIyEEb4uvtVSv1K7VKJX6gUpJfGLFpP4xRfYjh2Ly6JFVdqA+2bBUcE0NW9K\nj2Y9DFanofm5+PF3wt9k5mcavO49MXvwdvLG1szW4HUrtU8leqXOk3o9VxcuJHnFCuwffZQW771r\n0N2ccnW57InZw6CWg9AYGa5eQ+vj0ocCWcChq4cMWm9CdgKnk0+rYZsGTCV6pU6TOh1X3phLasA6\nHJ79D83fnGfwpYH3x+0nR5dTZ4dtrvN28sbS2NLg8+n3xu4F1CYjDZlaAkGps2R+PrGvzSZj+3Yc\nX56G4/PPV8v89uCoYGxMbejlbPidogzJRGNCL+deBr8hGxIbQjPLZjW+uYlSc1SPXqmT9Hl5xLw8\nnYzt22n22ms4vfBCtSR5bYGWXZd3MajlIEw0dX+1Rl9XX2IyY7icftkg9Wn1Wg7EHaCfa7869ZCY\nYlgq0St1jj47m8tTp5K5axfOb7+FwzNPV1tbh64eIkObUeeHba67PitmX5xhevXH44+Tqc1U4/MN\nnEr0Sp1SkJFB9LOTyT50mBYf/B/2EydWa3vBUcFYGlsWrydT17WyaYWrtavBplmGxIRgbGTMPS3u\nMUh9St2kEr1SZ+hSUoh++hly/vkH16VLsXvggeptT69jR/QOBrgNwExjmPn41U0IgZ+LH4evHkar\n11a5vj0xe/Bp7oOViZUBolPqKpXolTpBl5BA9JOTyDt3DrfPP6PJ8Puqvc2j146SkpdS59a2KY+v\niy9Z2iz+jv+7SvXEZsYSkRahZts0AirRK7VOe+UKUU88SX5MDC2/+RqbgQNrpN2gqCDMNeb1bpON\nXi16oRGaKg/f7I0pmlapxucbPJXolVqVf/kyUY89ji4xkVbLv8eqT82Mleulnr+i/8LP1Q9Lk6qv\nlVOTbExt6ObUrcqJPiQ2BDdrN1o3aW2YwJQ6SyV6pdZcT/L6rCxarVqFZY+aW37gn4R/SMhJqHfD\nNtf5uvgSnhROSm5Kpcrn6nI5dOUQ/d36q2mVjYBK9EqtkAUFxM2egz43l1arf8DCs0uNth8UFYSx\nkTED3AbUaLuG4ufih0Ry8MrBSpUPvRZKbkGuGrZpJFSiV2pF8urV5Bw9ivPcNzDvULNPZEopCY4K\npk+LPtiY2tRo24bS2aEztma2lR6+CYkJwVxjjk9zHwNHptRFKtErNS4/MpKEj5dhPXAgTfz9a7z9\n8ORw4rLi6s1DUqXRGGm4p8U97I/dj5TyjspKKdkTs4deLXphbmxeTREqdYlK9EqNkgUFxL0xF2Fm\nhvOCBbUyPhwcFYxGaBjUclCNt21Ivi6+xOfEE5EacUflItMjicmMob9r/2qKTKlrVKJXalTKjz+S\nc/Qozd94HZPmzWq8/evDNj7OPtiZV22P2dpW2eUQQmJCAOjrVr+mlSqVpxK9UmPyIyOJLxqysR0z\nplZiuJB6gcj0SIa1qr/DNtc5WznT1rbtHY/Th8SG0M62Ha7WrtUUmVLXVCjRCyGGCyHOCiEuCCHm\nlHJ+qhDihBDiuBBirxCic4lzrxeVOyuEqP7HHZU6Ser1xM2dhzA1rbUhGygcthEIhrgPqZX2Dc3X\nxZewa2Hk6nIrdH2WNovQa6H0d1PDNo1JuYleCKEBvgBGAJ2BR0om8iJrpZRdpZTewEfA0qKynYGJ\nQBdgOPBlUX1KI5Py44/khIXV2pDNdUHRQXRv1h1HC8dai8GQ/Fz9yCvI4+i1oxW6/uCVg+j0OjWt\nspGpSI++F3BBSnlRSpkPrANu+NwtpUwv8dIKuD4NYAywTkqZJ6W8BFwoqk9pRPIjI4lf+jHWAwYU\nD9nkF+SzOnw1LwS/YLC11csTlR7F+ZTz9fYhqdL0bN4TUyPTCg/fhMSEYGVihXcz72qOTKlLKpLo\nXYGSP4kxRcduIIR4UQgRQWGP/uU7LPucECJUCBGakJBQ0diVeqB4yMbEBOeFC5BIfrv4G/6b/Pno\nyEccvHKQx39/nNNJp6s9lqCoIACGtmo4id7C2IIezXtU6IaslJKQ2BB8XXwxMar7m6wohmOwm7FS\nyi+klO2A2cC8Oyz7rZTSR0rp4+TkZKiQlDrg3yGbNwjTX2Li1onMCZmDtYk13wz9hg3+GzDVmPL0\nH09z6IphN72+WXBUMJ4OnrSwblGt7dQ0XxdfLqReID47/rbXnUs5R3x2vFqtshGqSKKPBVqWeO1W\ndKws64DrC4nfaVmlAcmPiiJ+6cfg68Mcq9+Z/Odk0vLSeL/v+/w0+id8XX1pa9uW1SNW08KqBc8H\nP88fkX9USyxxmXGcSjrVoIZtrrs+zbK84ZuQ2KJplfVstU6l6iqS6I8AHkKINkIIUwpvrgaWvEAI\n4VHi5f3A+aKvA4GJQggzIUQbwAM4XPWwlbpO6vVEzplFnihgao/jnEg6yX99/kvg2EBGtxuNkfj3\nW8/ZyplVw1fh6ejJrN2zWHdmncHjCY4KBqjXT8OWpYN9BxwtHNkfW06ijwmhU9NOOFmqT82NjXF5\nF0gpdUKIl4A/AA2wQkp5SgixEAiVUgYCLwkhhgJaIAWYVFT2lBDiJyAc0AEvSikLqum9KHVEWl4a\nwYtn0vnYCVaOMmVMn6f4j+d/sDWzLbOMrZkt3w77lll7ZvHeofdIzEnkRe8XDTYNMzg6mA72HWjV\npJVB6qtLhBD4uviyJ2YPeqm/4ZfodWl5aRxPOM6zXZ+thQiV2lZuogeQUm4Dtt10bH6Jr6ffpux7\nwHuVDVCpP/IK8gg4HcDm3V/zVkAasV2b89pba3GxcalQeXNjcz4e+DELDyzkm3++ITEnkXn3zMPY\nqELfpmVKyE7gePxxnvd+vkr11GW+Lr4ERgRyOuk0XRxvXQl0f9x+9FKv5s83UlX7CVIUCjfx+O3i\nb3x27DOuZsax5HdrzMwtGfD5ekxsmt9RXcZGxizwXYCjhSPfnfiOlNwUPhrwUZX2dP0r+i8kskE8\nDVuW65t774/bX2qiD4kJwc7MDk8Hz5oOTakD1BIISqVJKdkXu4+HtjzEG3vfwN7cnlVZE3G7kEaL\n1+di0vzOkvx1Qghe7vEyc3rNYeflnUwJmkJ6fnr5BcsQHBVM6yataWfXrtJ11HUOFg50atqp1GmW\nBfoC9sbuxc/VD42Rel6xMVKJXqmU8KRwJgdNZmrwVDK1mXzY70P+1/VDLL//Bav+/bAdN7bKbTzW\n6TE+7P8hfyf8zVPbnyp3+mBpUnJTCL0WyjD3YQ1+JyVfF1/+jv+bLG3WDcdPJZ0iJS9FrVbZiKlE\nr9yRmIwYZu+ZzcNbH+Zs8llm3z2bwAcCGdF6ONfmvonQaGixcKHBkuqINiP4csiXxGbE8sS2J4hM\ni7yj8jsv76RAFjTIaZU383P1Qyd1HL5y48S2kNgQjIRR8TRMpfFRiV6pkNTcVD468hH+m/zZEb2D\nZ7s+y7Zx23i88+OYakxJWbOW7NBQmr8+BxNnZ4O23celDyuGryC3IJcnf3+Sk4knK1w2KCoIV2tX\nOjXtZNCY6iJvJ28sjC1umU8fEhNCN8du9X5ZZqXyVKJXypWUk8SYzWNYc3oNo9uNZuvYrUzvMb14\nG7786Gjily7Fql8/bMeNq5YYujh04YcRP2BpYskzfzxT7pxxgPT8dA5eOcjQVkMb/LANgInGhF7O\nvW5I9Ik5iZxKOqUWMWvkVKJXyrXt0jaSc5NZNXwVC3wX0Nzq35usUq/nytx5hUM27xhuyKY07k3c\nWT1iNa1sWvHiXy/y28Xfbnv97su70el1jWLY5jpfF1+iM6K5nFG4xNTe2L0AalplI6cSvVKuLRFb\n6OLQhe7Nut9yLmVtANlHjlTLkE1pnCydWDl8Jd7NvJkTMofV4avLvDY4KphmFs3o5tSt2uOqK66P\nwx+IOwAUDts4WThxl/1dtRmWUstUoldu61zKOU4nn2Z0u9G3nMu/fJn4JUuqdcimNDamNnw97GuG\nuQ/joyMf8XHYx7dskJ2tzWZf3D6GuA8p9UnRhsq9iTuu1q7si92HVq9lf9x++rn1axRDV0rZGs9P\ngFIpWyO2YiyMGdFmxA3HpV7PlTfmFs2yqfkdo8w0Zizqv4iHOjzEipMreHPfm+j0uuLzIbEh5BXk\nNci1bW5HCEEflz4cvnqY0KuhZGoz1WqVikr0StkK9AVsvbiVvm59aWre9IZzKQFFQzZzZmPSonaW\n/dUYaZh3zzxe8HqBzRGbmbFzBjm6HKBw2KapeVN6NOtRK7HVJj8XPzK1mXz191cYGxkXPzWrNF4q\n0StlOnTlEAk5CYxpd+NG3vmXLxO/eAlWfftiO358LUVXSAjB897P8+Y9b7InZg+T/5xMfHY8e2L2\nMKjloEb5JGivFr3QCA3H4o/Rs1lPrE2tazskpZapRK+UKfBiIE1Mm9wwY6N4lo2RUbXPsrkTD931\nEEsGLiE8KZxxgePI1mU3umGb65qYNqGrY1cANa1SAVSiV8qQpc3ir6i/GNFmBKYa0+LjKQEBZB8+\nTLNaHLIpyzD3YXwz7BsK9AU0MW1CL+fGuz2xn6sfoBK9UkitXqmUKigqiNyC3Btm2xTOslmKlZ8f\ndg8+WIvRle1u57v5afRPZGmzMNE03n1Rn+z8JF0du9LWtm1th6LUASrRK6UKjAjEvYk73RwL56AX\nD9kIUaeGbErT0qZl+Rc1cJYmlsW9ekVRQzfKLeIy4zhy9Qij244uTugp69YVDtnMfg0Tl4ptJKIo\nSt2gEr1yi60XtwIwqt0oALTX4gtn2fj6YjdhQm2GpihKJahEr9xASsmWiC34NPfB1doVgKTvv0fm\n5eH81vw6PWSjKErpVKJXbnAi8QSR6ZH4t/MHCnvzqevXYztmDKbu7rUcnaIolaESvXKDwIhAzDRm\nxXPQk77/HllQgOPUKbUcmaIolaUSvVIsvyCf7ZHbGdxqMNam1mjj40n96afC3nyrVrUdnqIolaQS\nvVIsJCaEtLy04mGbpO+/R+p0qjevKPWcSvRKscCIQBwtHLmnxT2Fvfn1qjevKA2BSvQKACm5KeyJ\n3cOotqMwNjJWvXlFaUBUolcA2B65HZ1ex+h2o//tzfv7q968ojQAKtErQOF2gR2bdqSDfQeSly9X\nvXlFaUBUole4mHaRE4knGN22sDefsm59YW9ezZtXlAZBJXqFLRFb0AgNI9uOVL15RWmAVKJv5PRS\nz5aILfi6+GKboVe9eUVpgFSib+SOXD3Ctexr+LfzV715RWmgKpTohRDDhRBnhRAXhBBzSjn/ihAi\nXAjxjxDiLyGEe4lzBUKI40V/Ag0ZvFJ1gRGBWJtY09fCs7A3P3q06s0rSgNTbqIXQmiAL4ARQGfg\nESFE55suOwb4SCm7ARuAj0qcy5FSehf98TdQ3LfIK8hjS8QW4jLjqquJBidbm01QVBD3tb6PrJU/\nFvbmn59a22EpimJgFenR9wIuSCkvSinzgXXAmJIXSCl3Simzi14eBNwMG2b5UnJTmLdvHhvObajp\npuutv6L/IkeXw2i7fqSsW6d684rSQFUk0bsCl0u8jik6Vpb/AL+XeG0uhAgVQhwUQjxQWgEhxHNF\n14QmJCRUIKRbOVs509e1L5subEKn11WqjsZmS8QWXK1dcd18WPXmFaUBM+jNWCHE44APsKjEYXcp\npQ/wKLBMCNHu5nJSym+llD5SSh8nJ6dKtz/eYzwJOQmExIRUuo7G4lrWNQ5eOch4h8GkqrF5RWnQ\nKpLoY4GSuy27FR27gRBiKDAX8JdS5l0/LqWMLfr7IrAL6F6FeG+rv1t/nCyc2Hh+Y3U1YTAJ2Qn8\nnfB3rbX/26XfkEgG7klTvXlFaeAqkuiPAB5CiDZCCFNgInDD7BkhRHfgGwqTfHyJ4/ZCCLOirx0B\nPyDcUMHfzNjImAfaP0BIbAhXs65WVzMGMSdkDk/+/iSHrhyq8ballAReCMTPrAsFv2xTvXlFaeDK\nTfRSSh3wEvAHcBr4SUp5SgixUAhxfRbNIsAa+PmmaZSdgFAhxN/ATuADKWW1JXqAse3Hopd6Nl3Y\nVJ3NVMn5lPMcvnoYjdAwa/esGv+lFJ4cTkRaBI8ds0Lm56t584rSwFVojF5KuU1K2UFK2U5K+V7R\nsflSysCir4dKKZvfPI1SSrlfStlVSulV9Pfy6nsrhVo2aUnvFr359fyv6KW+upurlHVn1mGmMWPF\nfSvI1+czc+dM8gryyi9oIFsituCUbYLTH2GFvfnWrWusbUVRal6DfDL2QY8HicuK42DcwdoO5Rbp\n+elsubiFEW1G4N3Mm/f83uNk0kn+79D/1Uj7Wr2WbRe3MfWUMzJfq8bmFaURaJCJfnCrwdiZ2bHh\nfN2bU7/5wmZydDk82vFRAIa4D2Fy18lsPL+Rjeeq/ybyvth96JOT8QyJUb15RWkkGmSiN9WY4t/O\nn52Xd5KUk1Tb4RTTSz3rzqyje7PudHLoVHz8Re8X8XXx5b1D73Ei4US1xhAYEchDoaYIbYHqzStK\nI9EgEz0UzqnX6XUERtSd5XX2xu4lOiOaRzo+csNxjZGGD/t9iJOFE6/sfoXk3ORqaT8tL42jp3cy\nKDRf9eYVpRFpsIm+rV1bujfrzi/nf0FKWdvhABBwJgAnCyeGthp6yzk7czs+HvQxKbkpvLb7tWp5\nuvePyD8YeSAPjU6q3ryiNCINNtFDYa8+Mj2SsGthtR0KUelR7I3dy4QOEzDRmJR6TWeHzrx5z5sc\nunqIT49+avAYdhz/hfuOge2oUao3ryiNSINO9Pe2vhcbE5s68aTsujPrMDYyZsJdE2573Zj2Y3j4\nrodZeWolf0T+YbD2o9OjabPtH0wKUL15RWlkGnSitzC2YGTbkQRFBZGWl1ZrcWRrs9l0YRPD3Ifh\naOFY7vWz756Nl5MXb+57k4jUCIPEsP3Yeu4Lk5iNGIZZmzYGqVNRlPqhQSd6gAc7PEheQR5bL26t\ntRi2XtxKpjazeEpleUw0JiwZsARLY0tm7JxBRn5GldrXSz3a1RswKQC3l2ZUqS5FUeqfBp/oOzbt\nSGeHzmw8v7FWbspKKQk4E0Cnpp3wcvKqcLnmVs1ZMnAJMRkxzN07t0pP+R47uwu/g+lkDuqhevOK\n0gg1+EQPhTdlz6ec52TiyRpv+8jVI1xIvcCjnR5FCHFHZXs278mrPq+y8/JOlp+o/OoRUV9/ikkB\ndJw5r9J1KIpSfzWKRD+yzUgsjC1q5abs2jNrsTOzY0SbEZUq/1inxxjZZiSfHfuMfbH77rh81rU4\n2v51lsjeLbH16FR+AUVRGpxGkeitTa0Z3no42y5tI0ubVWPtxmXGsfPyTsZ7jMdMY1apOoQQvNXn\nLTzsPZgdMpuYjJg7Kn/is3cx0UGz51+sVPuKotR/jSLRA4zvMJ4cXQ6/X/q9/IsN5KezPwHw8F0P\nV6keSxNLlg1chl7qmblrJrm63AqV0yUlYRm4m7BulvTsNbpKMSiKUn81mkTfzbEb7e3a18jCYQC5\nulw2nt/IoJaDaGHdosr1tWzSkg/6fcDZ5LO8c/CdCt1Yjvn2CzRaPflP+GMkGs1/taIoN2k0P/1C\nCMZ7jOdk0knOJp+t9va2R24nNS+1wlMqK6K/W3+e93qewIhA1p9df9trdUlJZK7bwN7OgsH9njBY\nDIqi1D+NJtEDjG43GlMj02q/KSulZO3ptbS3a8/dzncbtO4pXlMY4DaADw9/yPH442Vel7xyJSJf\ny8lRHWlr29agMSiKUr80qkRva2bLUPehbL24tcLj3JXxd8LfnE4+zSMdH7njKZXlMRJGvN/vfVpY\nt+CVXa+QmJN4yzW65GSSfvyRvZ0Fvn1uv+SCoigNX6NK9FD4pGxGfgZBUUHV1sbaM2uxMbFhVNtR\n1VJ/E9MmLBu0jExtJq/uehWtXnvD+eQVK5B5+WzuZ8Lw1sOrJQZFUeqPRpfofZr70MqmFRvOVc/u\nUwnZCQRFBjGm/RgsTSyrpQ2ADvYdeLvP2xyNP8qS0CXFx3XJySSvWcuRrmZ4dBuIvbl9tcWgKEr9\n0OgSvRCCcR7jOBp/lItpFw1e/4ZzG9BJ3S2bi1SHkW1H8ninx1lzek3xWj5Jy5ejz8tl7T1a/Nv5\nV3sMiqLUfY0u0UPhUsDGwphfz/9q0Hq1BVp+OvcTfV370qpJK4PWXZZXfF6hZ/OeLNi/gDPfLiV5\nxUoieruS5WJHP7d+NRKDoih1W6NM9I4WjgxsOZDAiEC0BdryC1RQcHQwiTmJBp1SWR4TIxMW9V/E\nIyEgl36Hcf8+vN8/meGth2OqMa2xOBRFqbsaZaKHwidlk3OT2XF5h8HqXHt6La1sWuHn6mewOssj\nCwrQffA5I3ZnstNLw9SBEWQa5athG0VRijXaRN+nRR9aWLUw2JOy4UnhHE84zsSOE2vsKVR9Xh6x\nM2aS+tNPOEyZguOCN4nPT6J1k9Z0dexaIzEoilL3Gdd2ALVFY6RhbPuxfPn3l8RkxOBm41al+gLO\nBGBhbMGY9mMMFOHtFWRkEPPCi2QfOULzN96g6ZNPMEFK8vVa2tm1M/j8fUVR6q9G26MHGOsxFiNh\nxK8XqnZTNjU3lW0XtzG67WiamDYxUHRl0yUkEPXEk2QfO4bLokU0fbJwiQMhBI93fpw+Ln2qPQZF\nUeqPRp3ona2c8XPxY9P5Tej0ukrXs/H8RvL1+UzsONGA0ZUuPzqayEcfIz86mpZff43t6Op5KEtR\nlIajUSd6KLwpG58Tz97YvZUqX6AvYP3Z9fRy7oWHvYeBo7tRbng4kY88ij4jA/dVK7HuW3M3fRVF\nqb8afaLv79YfRwvHSt+U3RWziytZV6p9SmXWwUNEPfEkwswU97VrsejWrVrbUxSl4Wj0id7EyIQx\n7cawJ3YP17Ku3XH5gNMBOFs5M6DlgGqIrlD69j+4PHkyJi4taB0QgFlbtcG3oigVV6FEL4QYLoQ4\nK4S4IISYU8r5V4QQ4UKIf4QQfwkh3EucmySEOF/0Z5IhgzeU8R7j0Us9myM231G5iNQIDl09xMN3\nPYyxUfVMYEpZt47YmTMx9/TEffVqTJo3r5Z2FEVpuMpN9EIIDfAFMALoDDwihOh802XHAB8pZTdg\nA/BRUdmmwFtAb6AX8JYQos6tstWySUt6O/fml/O/oJf6G87pkpJI/PY7ck6dumVXp4AzAZgamTLe\nY7zBY5JSkvD5F1x9ewHWAwbQasVyNHZ2Bm9HUZSGryI9+l7ABSnlRSllPrAOuGGyuJRyp5Qyu+jl\nQeD6pPT7gCApZbKUMgUIAurkurnjO4wnNjOWg1cOFh+TWi0x06eTsHQpkeMf5JK/P4nffYf26lUy\n8jMIjAhkRJsRBl8hUhYUcO2dd0j8/HNsx47F7fPPMLKwMGgbiqI0HhUZb3AFLpd4HUNhD70s/wGu\n78BdWlnXmwsIIZ4DngNo1apmFgO72ZBWQ7Azs2PjuY34uvgCEL94MTmhYTgvWABSkhYYSMKSpSQs\n/Zh0T3d6tcrikX4PGDQOfX4+ca/NJmP7dhye/Q9Or76qHn5SFKVKDDqwLIR4HPAB7ujOpJTyW+Bb\nAB8fn/J3va4GphpTRrcbTcCZAJJzk9EEHyD5fz9g/+QT2D/8EAD2Ex8mPzqa1MBAEtd+w4sn9Ii/\nJhM7dCi2Y/yx6tMH+FMxZgAADBRJREFUYVz5f9KCzExiXppG9sGDNJs9G4ennzLQu1MUpTGrSFaK\nBVqWeO1WdOwGQoihwFxggJQyr0TZgTeV3VWZQGvCeI/xrA5fTfCO5XR7MwCLnj1pPmvWDdeYtmrF\nubHevGAtWeY0jc6hCaRv+530rVvRODliO/J+bMf4Y9ap0x31xHWJiVx+bgq5587h8tGH2PqrRckU\nRTEMcfMNxlsuEMIYOAcMoTBxHwEelVKeKnFNdwpvwg6XUp4vcbwpEAb0KDp0FOgppUwuqz0fHx8Z\nGhpauXdjAM9ufIRJS0/RXNjS5peNmDRrdss1L/71IuFJ4fw5/k9MNCbo8/PJ3L2b9MBAMnbtBq0W\nMw8PbMf402T06HJnyuTHxBD9n/+gi0/A7ZNlWPfvX11vT1GUBkoIESal9CntXLk9eimlTgjxEvAH\noAFWSClPCSEWAqFSykBgEWAN/FzUi42WUvpLKZOFEO9Q+MsBYOHtknxtk3o9UzbnYZ6iJevTF0pN\n8pfTLxMSE8JUr6mYaEwAMDI1pcmwYTQZNoyC1FTSt28nbdNm4hcvIX7JUizv6Y3tmDE0GTYMIyur\nG+rLPXOG6MmTIV+L+8oVWHh718h7VRSl8Si3R1/TarNHn/jVVyR88ilrhlugHz+c9/u9f8s1Hx35\niIDT/9/evcdIVd5hHP8+sCwsFxFkpcACayniUqtIjPGSGoP3GzRegmgbe/nDVgRs1aK1aUSssWit\ngNZG8ZZKUIMW0YiXommptfWKKKKieGERFFRWKLqy8Osfc9ABdheQ3T0zZ55Pspkz78yeeWYy85t3\n3pnzvrN47IzH2Lvz9m8E+b587z3q5j5E3dy5bFy+HFVU0O2YY+g+ciRdDj+MDS+8QO35Y2nXtSsD\nbptBx0GDWuuumVnG7VaPvlSsX7CA1dOms8epp9LptG7MeftBJh4yke4du391nQ0bNzBn6RyOHXjs\nDos8QPnAgVSOu4BeF4zl85deou7BuXw2bx6fPfQQZZWVbKqro0P//gyYcSsd+vRpzbtnZiWs5KdA\ngNwY+YqLL6HjvvvS58pJnLbv6dRvqueRdx7Z6noPL3uYdRvXMaZm1xb+lkTn4cPpM+kKBv9rAf2m\nTqXTAQfQ+bBDGXj3X13kzaxVlXyPfvMXX1A7bjxEUDV9Gu0qKhhaMZSanjXc/+b9nDXkLCQREcx6\nfRY1PWsYVvnNx9HblZezx/HHscfxx7XgvTAza1pJ9+gjglVXTKJ+yRL6TvkD5XkHa52x7xm88ekb\nLP449+Oi5z98nrfWvsWY/cb4ACYzKyolXejX3nsvdXPm0Ov88+l21FFbXXbSPidRUVbB7DdnA7l5\nbfbsuCcn7nNiCknNzL65ki30ny9cyKrfX02XI79PrwvGbnd51/KuHF99PPPemceytct48v0nOW3w\naXQq65RCWjOzb64kC33DmjXUTriQDr1702/KFNSu8Yfh9MGns6FhAxOemkAQjB4yuo2TmpntvpL7\nMjYaGljxq4vYtHYt1ffManbq3wMrD2RQ90G8Xfc2I/qPoG/Xvm2Y1MysZZRcj/6jP17Phmefpc+V\nk+hUU9PsdSVx5pAzATi7pnWXCjQzay0l1aP/bN48PrnjDnqcfTbdR43a8T8Ao4eMpqZnDcN7D9/x\nlc3MClDJ9Ojrly7lg8t/S8WwYfS+dOJO/19ZuzIXeTMraiVR6DetW0ftuPG0q6ig39QbUHl52pHM\nzNpM5oduYvNmPrjsMr5cvpwBd9zuxbXNrORkvkf/8a0zWP/3+ex9ycV0OeSQtOOYmbW5TBf69U8/\nzeqpU9njpBPpee65accxM0tFZgv9xhUr+OCii+k46Nv0mTzZ89OYWcnKZKHfXF9P7fgJREMDVdOn\nb7eqk5lZKcnkl7GrJk/mi8WLqbrpRsqrq9OOY2aWqsz16D+97z7qZt/PXuedR7ejj047jplZ6jJV\n6D9ftIgPJ19FlyOOoHL8uLTjmJkVhMwU+oZPPqF2woWUVVbS97prUfv2aUcyMysI2Rmjl+i03370\nGjuWsh490k5jZlYwMlPoy3r0oP/Nf047hplZwcnM0I2ZmTXOhd7MLONc6M3MMs6F3sws41zozcwy\nzoXezCzjXOjNzDLOhd7MLOMUEWln2Iqk1cB7u7GLXsCaForT2oopKxRX3mLKCsWVt5iyQnHl3Z2s\nAyOisrELCq7Q7y5Jz0fEwWnn2BnFlBWKK28xZYXiyltMWaG48rZWVg/dmJllnAu9mVnGZbHQ35J2\ngF1QTFmhuPIWU1YorrzFlBWKK2+rZM3cGL2ZmW0tiz16MzPL40JvZpZxmSn0kk6Q9IaktyRdmnae\n5kjqL+kpSa9JWixpQtqZdkRSe0kvSXo47Sw7ImlPSbMlvS5piaTD0s7UFEm/TJ4Dr0qaJalT2pny\nSbpd0keSXs1r6ynpCUlLk9OCWNKtiazXJs+DRZL+JmnPNDPmayxv3mUXSQpJvVritjJR6CW1B24C\nTgSGAmMkDU03VbMagIsiYihwKDC2wPMCTACWpB1iJ00FHo2I/YADKdDckvoB44GDI2J/oD1wVrqp\ntnMncMI2bZcC8yNiMDA/OV8I7mT7rE8A+0fEAcCbwGVtHaoZd7J9XiT1B44D3m+pG8pEoQcOAd6K\niGUR8SVwDzAq5UxNioiVEfFisr2OXCHql26qpkmqAk4GZqSdZUckdQeOBG4DiIgvI2JtuqmaVQZU\nSCoDOgMfpJxnKxHxT+CTbZpHAXcl23cBP2jTUE1oLGtEPB4RDcnZ/wBVbR6sCU08tgB/An4NtNgv\nZbJS6PsBy/PO11LAhTOfpGrgIOC/6SZp1g3knnib0w6yE/YBVgN3JENNMyR1STtUYyJiBXAduZ7b\nSqAuIh5PN9VO6R0RK5PtVUDvNMPsgp8C89IO0RxJo4AVEfFyS+43K4W+KEnqCtwPXBgRn6WdpzGS\nTgE+iogX0s6yk8qA4cDNEXEQ8D8KZ2hhK8nY9ihyb059gS6Sfphuql0Tud9nF/xvtCVdTm7IdGba\nWZoiqTPwG+B3Lb3vrBT6FUD/vPNVSVvBktSBXJGfGREPpJ2nGUcAIyW9S25IbISku9ON1KxaoDYi\ntnxCmk2u8BeiY4B3ImJ1RGwEHgAOTznTzvhQUh+A5PSjlPM0S9KPgVOAc6KwDxwaRO5N/+Xk9VYF\nvCjpW7u746wU+ueAwZL2kVRO7gutuSlnapIkkRtDXhIR16edpzkRcVlEVEVENbnH9cmIKNheZ0Ss\nApZLGpI0HQ28lmKk5rwPHCqpc/KcOJoC/eJ4G3OBc5Ptc4EHU8zSLEknkBt2HBkRG9LO05yIeCUi\n9o6I6uT1VgsMT57TuyUThT75suUC4DFyL5T7ImJxuqmadQTwI3K944XJ30lph8qQccBMSYuAYcDV\nKedpVPKpYzbwIvAKuddjQR2uL2kW8AwwRFKtpJ8B1wDHSlpK7lPJNWlm3KKJrDcC3YAnktfZX1IN\nmaeJvK1zW4X9ScbMzHZXJnr0ZmbWNBd6M7OMc6E3M8s4F3ozs4xzoTczyzgXeisZkjbl/Zx1YUvO\nciqpurFZCM0KQVnaAcza0OcRMSztEGZtzT16K3mS3pU0RdIrkp6V9J2kvVrSk8lc5vMlDUjaeydz\nm7+c/G2ZtqC9pFuT+eUfl1SRXH98svbAIkn3pHQ3rYS50Fspqdhm6GZ03mV1EfE9ckdS3pC0TQfu\nSuYynwlMS9qnAf+IiAPJzaOz5SjswcBNEfFdYC1wetJ+KXBQsp+ft9adM2uKj4y1kiFpfUR0baT9\nXWBERCxLJptbFRF7SVoD9ImIjUn7yojoJWk1UBUR9Xn7qAaeSBbjQNJEoENEXCXpUWA9MAeYExHr\nW/mumm3FPXqznGhie1fU521v4uvvwE4mtwLacOC5ZJERszbjQm+WMzrv9Jlk+998vbTfOcCCZHs+\n8Av4ai3d7k3tVFI7oH9EPAVMBLoD232qMGtN7llYKamQtDDv/KMRseUnlj2S2S7rgTFJ2zhyK1Vd\nQm7Vqp8k7ROAW5LZBjeRK/oraVx74O7kzUDAtAJf2tAyyGP0VvKSMfqDI2JN2lnMWoOHbszMMs49\nejOzjHOP3sws41zozcwyzoXezCzjXOjNzDLOhd7MLOP+D5OWXTZuXZgzAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEGCAYAAAB1iW6ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "val accuracy 0.41379310344827586\n",
            "val loss 1.418855686493108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1kgj76dvQxIJ"
      },
      "source": [
        "**Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_dKdDvgnQw7d",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "# todo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUIpGmogDgOC",
        "colab_type": "text"
      },
      "source": [
        "**Random search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1eOsPQVDgG6",
        "colab_type": "code",
        "outputId": "687afb54-31f7-41c8-a0a9-974e6c305eb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "best_accuracy = 0.0\n",
        "best_loss = 0.0\n",
        "val_accuracies = []\n",
        "val_losses = []\n",
        "import random\n",
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-672'\n",
        "#TRAIN_DATA_DIR = 'Homework2-Caltech101/101_ObjectCategories'\n",
        "compose=[transforms.Resize(224),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.RandomGrayscale(),\n",
        "        transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
        "        transforms.ToTensor()\n",
        "        ]\n",
        "train_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\n",
        "train_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]\n",
        "val_indexes = [idx for idx in range(len(train_dataset)) if not idx % 5]\n",
        "val_dataset = Subset(val_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "print('training set {}'.format(len(train_dataset)))\n",
        "print('validation set {}'.format(len(val_dataset)))\n",
        "best_net = vgg11()\n",
        "best_net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "best_net = best_net.to(DEVICE)\n",
        "best_set = {}\n",
        "N = 50\n",
        "for i in range(N):\n",
        "  BATCH_SIZE = int(random.uniform(8, 16))\n",
        "  LR = random.uniform(0.0008, 0.004)\n",
        "  MOMENTUM = 0.9\n",
        "  WEIGHT_DECAY = 10**random.uniform(-5, -3)\n",
        "  NUM_EPOCHS = 35\n",
        "  STEP_SIZE = 21\n",
        "  GAMMA = 10**random.uniform(-2, 0)\n",
        "  set = {\"lr\": LR, \"batch_size\": BATCH_SIZE, \"weight_decay\": WEIGHT_DECAY, \"gamma\": GAMMA}\n",
        "  print(\"-------------------------------------\")\n",
        "  \n",
        "  net = vgg11()\n",
        "  net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "  current_net, val_accuracy, val_loss = train_network(net, net.parameters(), LR, NUM_EPOCHS, BATCH_SIZE, WEIGHT_DECAY, STEP_SIZE, GAMMA, train_dataset, val_dataset=val_dataset, verbosity=True)\n",
        "\n",
        "  val_accuracies.append(val_accuracy)\n",
        "  val_losses.append(val_loss)\n",
        "\n",
        "  if val_accuracy > best_accuracy:\n",
        "    best_accuracy = val_accuracy\n",
        "    best_loss = val_loss\n",
        "    best_net = copy.deepcopy(current_net)\n",
        "    best_set = copy.deepcopy(set)\n",
        "\n",
        "  print(\"lr {}, batch {}, decay {}, gamma {}, val accuracy {}, val loss {} [{} / {}]\".format(LR, BATCH_SIZE, WEIGHT_DECAY, GAMMA, val_accuracy, val_loss, i+1, N))\n",
        "\n",
        "print(\"--------------------------------------------\")\n",
        "print(\"\\n{}, best val accuracy {}, best val loss {}\".format(best_set, best_accuracy, best_loss))\n",
        "print(\"val accuracies\\n{}\".format(val_accuracies))\n",
        "print(\"val losses\\n{}\".format(val_losses))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set 809\n",
            "validation set 203\n",
            "-------------------------------------\n",
            "train_acc: 0.1841779975278121, val_acc: 0.2315270935960591, train_loss: 1.7710324662872239, val_loss: 1.7467262656817883 (1 / 35)\n",
            "train_acc: 0.2360939431396786, val_acc: 0.2019704433497537, train_loss: 1.7491115103251265, val_loss: 1.7438402651566003 (2 / 35)\n",
            "train_acc: 0.28059332509270707, val_acc: 0.2413793103448276, train_loss: 1.6514052005279787, val_loss: 1.6914695947628302 (3 / 35)\n",
            "train_acc: 0.22991347342398022, val_acc: 0.1921182266009852, train_loss: 1.7497405879135037, val_loss: 1.783629024557292 (4 / 35)\n",
            "train_acc: 0.2088998763906057, val_acc: 0.18226600985221675, train_loss: 1.7697573770551362, val_loss: 1.7520633794991254 (5 / 35)\n",
            "train_acc: 0.276885043263288, val_acc: 0.30049261083743845, train_loss: 1.6978493671040011, val_loss: 1.5821349879203759 (6 / 35)\n",
            "train_acc: 0.29295426452410384, val_acc: 0.2857142857142857, train_loss: 1.639930427590171, val_loss: 1.675443747947956 (7 / 35)\n",
            "train_acc: 0.3411619283065513, val_acc: 0.29064039408866993, train_loss: 1.5796817651637847, val_loss: 1.538491714764111 (8 / 35)\n",
            "train_acc: 0.3411619283065513, val_acc: 0.3793103448275862, train_loss: 1.4894252515988533, val_loss: 1.353819059327318 (9 / 35)\n",
            "train_acc: 0.3695920889987639, val_acc: 0.4039408866995074, train_loss: 1.4729417226517894, val_loss: 1.3341451965529343 (10 / 35)\n",
            "train_acc: 0.3621755253399258, val_acc: 0.42857142857142855, train_loss: 1.4148757353111898, val_loss: 1.3007458034407329 (11 / 35)\n",
            "train_acc: 0.36341161928306553, val_acc: 0.3842364532019704, train_loss: 1.4275510327335637, val_loss: 1.342622566105697 (12 / 35)\n",
            "train_acc: 0.3720642768850433, val_acc: 0.4729064039408867, train_loss: 1.4431874467651689, val_loss: 1.303438945944086 (13 / 35)\n",
            "train_acc: 0.3930778739184178, val_acc: 0.45320197044334976, train_loss: 1.3645190276085815, val_loss: 1.2934145445894139 (14 / 35)\n",
            "train_acc: 0.39060568603213847, val_acc: 0.4433497536945813, train_loss: 1.3782285674393397, val_loss: 1.2535211429220114 (15 / 35)\n",
            "train_acc: 0.4004944375772559, val_acc: 0.4088669950738916, train_loss: 1.3082860633086215, val_loss: 1.417262525981283 (16 / 35)\n",
            "train_acc: 0.4338689740420272, val_acc: 0.3793103448275862, train_loss: 1.3100111936904002, val_loss: 1.3874700709516778 (17 / 35)\n",
            "train_acc: 0.453646477132262, val_acc: 0.4433497536945813, train_loss: 1.2510992443311053, val_loss: 1.2312383228922126 (18 / 35)\n",
            "train_acc: 0.4956736711990111, val_acc: 0.47783251231527096, train_loss: 1.2142145204897716, val_loss: 1.2065272836262368 (19 / 35)\n",
            "train_acc: 0.5377008652657602, val_acc: 0.4630541871921182, train_loss: 1.0956836364177898, val_loss: 1.3047876131945644 (20 / 35)\n",
            "train_acc: 0.5574783683559951, val_acc: 0.4630541871921182, train_loss: 1.0951354323859857, val_loss: 1.2384144725470707 (21 / 35)\n",
            "train_acc: 0.6402966625463535, val_acc: 0.5566502463054187, train_loss: 0.9108578375597083, val_loss: 1.1795575680403874 (22 / 35)\n",
            "train_acc: 0.6674907292954264, val_acc: 0.5911330049261084, train_loss: 0.8434769672206954, val_loss: 1.1246547951486898 (23 / 35)\n",
            "train_acc: 0.6724351050679852, val_acc: 0.5862068965517241, train_loss: 0.790926190072438, val_loss: 1.1062244714187284 (24 / 35)\n",
            "train_acc: 0.7119901112484549, val_acc: 0.5960591133004927, train_loss: 0.7454302578390897, val_loss: 1.1751771566315825 (25 / 35)\n",
            "train_acc: 0.7045735475896168, val_acc: 0.5911330049261084, train_loss: 0.709259114763498, val_loss: 1.1652706608983683 (26 / 35)\n",
            "train_acc: 0.7515451174289246, val_acc: 0.5812807881773399, train_loss: 0.6368649597147339, val_loss: 1.2072312030298957 (27 / 35)\n",
            "train_acc: 0.7416563658838071, val_acc: 0.5566502463054187, train_loss: 0.6191763486091522, val_loss: 1.1284732105109492 (28 / 35)\n",
            "train_acc: 0.7849196538936959, val_acc: 0.5714285714285714, train_loss: 0.5890785379079717, val_loss: 1.1515678384621155 (29 / 35)\n",
            "train_acc: 0.7737948084054388, val_acc: 0.6206896551724138, train_loss: 0.5569975733093927, val_loss: 1.199758934563604 (30 / 35)\n",
            "train_acc: 0.7985166872682324, val_acc: 0.5812807881773399, train_loss: 0.5258476126695003, val_loss: 1.2652237976125895 (31 / 35)\n",
            "train_acc: 0.8244746600741656, val_acc: 0.5960591133004927, train_loss: 0.46963487880486343, val_loss: 1.2663611285204959 (32 / 35)\n",
            "train_acc: 0.8491965389369592, val_acc: 0.6009852216748769, train_loss: 0.4279424289543048, val_loss: 1.293110381206268 (33 / 35)\n",
            "train_acc: 0.8553770086526576, val_acc: 0.5763546798029556, train_loss: 0.40204033568704084, val_loss: 1.3243666696431013 (34 / 35)\n",
            "train_acc: 0.8800988875154512, val_acc: 0.6206896551724138, train_loss: 0.34771451354026794, val_loss: 1.301346871653214 (35 / 35)\n",
            "lr 0.0048979615247910675, batch 12, decay 0.0007368105157485125, gamma 0.09877903626081189, val accuracy 0.6206896551724138, val loss 1.199758934563604 [1 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.1792336217552534, val_acc: 0.18226600985221675, train_loss: 1.7736480511605224, val_loss: 1.7526064917371778 (1 / 35)\n",
            "train_acc: 0.21137206427688504, val_acc: 0.2561576354679803, train_loss: 1.7443042594216516, val_loss: 1.6376527735752424 (2 / 35)\n",
            "train_acc: 0.273176761433869, val_acc: 0.35467980295566504, train_loss: 1.654656814703688, val_loss: 1.5745465053713381 (3 / 35)\n",
            "train_acc: 0.18046971569839307, val_acc: 0.22167487684729065, train_loss: 1.7715205008668276, val_loss: 1.7590791080972832 (4 / 35)\n",
            "train_acc: 0.1965389369592089, val_acc: 0.18226600985221675, train_loss: 1.7585067292226406, val_loss: 1.7670292220092172 (5 / 35)\n",
            "train_acc: 0.25710754017305315, val_acc: 0.2660098522167488, train_loss: 1.71813655842662, val_loss: 1.664226038115365 (6 / 35)\n",
            "train_acc: 0.27070457354758964, val_acc: 0.2857142857142857, train_loss: 1.6743396380628437, val_loss: 1.7453631238984357 (7 / 35)\n",
            "train_acc: 0.29295426452410384, val_acc: 0.2561576354679803, train_loss: 1.6124028073547798, val_loss: 1.6032950164649287 (8 / 35)\n",
            "train_acc: 0.3164400494437577, val_acc: 0.21674876847290642, train_loss: 1.5707165643812258, val_loss: 1.7263645591406986 (9 / 35)\n",
            "train_acc: 0.3288009888751545, val_acc: 0.3694581280788177, train_loss: 1.542294026157912, val_loss: 1.4088075296044937 (10 / 35)\n",
            "train_acc: 0.37453646477132263, val_acc: 0.4088669950738916, train_loss: 1.4295319744624078, val_loss: 1.3160603933146435 (11 / 35)\n",
            "train_acc: 0.34487021013597036, val_acc: 0.42857142857142855, train_loss: 1.4427891269749853, val_loss: 1.3269020213282168 (12 / 35)\n",
            "train_acc: 0.36093943139678614, val_acc: 0.45320197044334976, train_loss: 1.3894022937463446, val_loss: 1.2865488235586382 (13 / 35)\n",
            "train_acc: 0.4177997527812114, val_acc: 0.4039408866995074, train_loss: 1.345461735619308, val_loss: 1.3598436751389151 (14 / 35)\n",
            "train_acc: 0.4437577255871446, val_acc: 0.4827586206896552, train_loss: 1.3195575331285947, val_loss: 1.3616349409366477 (15 / 35)\n",
            "train_acc: 0.41903584672435107, val_acc: 0.4433497536945813, train_loss: 1.2938431704736906, val_loss: 1.2985044688426803 (16 / 35)\n",
            "train_acc: 0.4635352286773795, val_acc: 0.4433497536945813, train_loss: 1.226008664986996, val_loss: 1.3651997626121408 (17 / 35)\n",
            "train_acc: 0.4647713226205192, val_acc: 0.43349753694581283, train_loss: 1.2361429562822113, val_loss: 1.2307789522438801 (18 / 35)\n",
            "train_acc: 0.4956736711990111, val_acc: 0.4039408866995074, train_loss: 1.189627605846108, val_loss: 1.3760334000798868 (19 / 35)\n",
            "train_acc: 0.5315203955500618, val_acc: 0.5024630541871922, train_loss: 1.178057996613723, val_loss: 1.2655104225492242 (20 / 35)\n",
            "train_acc: 0.5377008652657602, val_acc: 0.4482758620689655, train_loss: 1.1166344041877387, val_loss: 1.2910583019256592 (21 / 35)\n",
            "train_acc: 0.5995055624227441, val_acc: 0.5714285714285714, train_loss: 1.026062799030535, val_loss: 1.103880543133308 (22 / 35)\n",
            "train_acc: 0.630407911001236, val_acc: 0.5862068965517241, train_loss: 0.8652822756944097, val_loss: 1.0928738686838761 (23 / 35)\n",
            "train_acc: 0.6724351050679852, val_acc: 0.5763546798029556, train_loss: 0.7871297903644434, val_loss: 1.1020997507231576 (24 / 35)\n",
            "train_acc: 0.695920889987639, val_acc: 0.5960591133004927, train_loss: 0.7807023369042924, val_loss: 1.091816563030769 (25 / 35)\n",
            "train_acc: 0.7119901112484549, val_acc: 0.5714285714285714, train_loss: 0.7453222184157636, val_loss: 1.1042851650068912 (26 / 35)\n",
            "train_acc: 0.7379480840543882, val_acc: 0.5862068965517241, train_loss: 0.7068870488291765, val_loss: 1.1036973780599133 (27 / 35)\n",
            "train_acc: 0.7416563658838071, val_acc: 0.6059113300492611, train_loss: 0.6629525985941751, val_loss: 1.1093842064218569 (28 / 35)\n",
            "train_acc: 0.7367119901112484, val_acc: 0.6059113300492611, train_loss: 0.6489057744057718, val_loss: 1.1206492501233012 (29 / 35)\n",
            "train_acc: 0.7441285537700866, val_acc: 0.5911330049261084, train_loss: 0.647850553022769, val_loss: 1.0941240554079046 (30 / 35)\n",
            "train_acc: 0.7601977750309024, val_acc: 0.5862068965517241, train_loss: 0.603501689227756, val_loss: 1.1157133259209506 (31 / 35)\n",
            "train_acc: 0.7824474660074165, val_acc: 0.6059113300492611, train_loss: 0.5613979977568236, val_loss: 1.1163707137695087 (32 / 35)\n",
            "train_acc: 0.7911001236093943, val_acc: 0.6108374384236454, train_loss: 0.5727301674661295, val_loss: 1.1637333679962627 (33 / 35)\n",
            "train_acc: 0.799752781211372, val_acc: 0.6206896551724138, train_loss: 0.5303083510496118, val_loss: 1.1612589919361576 (34 / 35)\n",
            "train_acc: 0.8034610630407911, val_acc: 0.6157635467980296, train_loss: 0.5214012133139467, val_loss: 1.1499783876787852 (35 / 35)\n",
            "lr 0.005563517269754794, batch 10, decay 0.0007977701264559719, gamma 0.03556976073448573, val accuracy 0.6206896551724138, val loss 1.1612589919361576 [2 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.16440049443757726, val_acc: 0.22167487684729065, train_loss: 1.7805145807997111, val_loss: 1.7559497156753916 (1 / 35)\n",
            "train_acc: 0.21508034610630408, val_acc: 0.29064039408866993, train_loss: 1.747242243387201, val_loss: 1.7354320046936937 (2 / 35)\n",
            "train_acc: 0.29295426452410384, val_acc: 0.3054187192118227, train_loss: 1.6598902859705487, val_loss: 1.588314405215785 (3 / 35)\n",
            "train_acc: 0.28182941903584674, val_acc: 0.2857142857142857, train_loss: 1.654859683422282, val_loss: 1.6462655302339 (4 / 35)\n",
            "train_acc: 0.207663782447466, val_acc: 0.2857142857142857, train_loss: 1.7650609595519209, val_loss: 1.698088478572263 (5 / 35)\n",
            "train_acc: 0.24969097651421507, val_acc: 0.29064039408866993, train_loss: 1.7321900861667026, val_loss: 1.6020249480684403 (6 / 35)\n",
            "train_acc: 0.2830655129789864, val_acc: 0.33497536945812806, train_loss: 1.6736535905170795, val_loss: 1.6001322668761455 (7 / 35)\n",
            "train_acc: 0.30778739184178, val_acc: 0.37438423645320196, train_loss: 1.5595755338374115, val_loss: 1.4167115535642125 (8 / 35)\n",
            "train_acc: 0.32509270704573545, val_acc: 0.3399014778325123, train_loss: 1.5297795299841241, val_loss: 1.4671604169413375 (9 / 35)\n",
            "train_acc: 0.3535228677379481, val_acc: 0.3891625615763547, train_loss: 1.4539535875226128, val_loss: 1.458125835569034 (10 / 35)\n",
            "train_acc: 0.37824474660074164, val_acc: 0.3497536945812808, train_loss: 1.4263694710725612, val_loss: 1.3368913187769247 (11 / 35)\n",
            "train_acc: 0.3967861557478368, val_acc: 0.39901477832512317, train_loss: 1.3771792264155611, val_loss: 1.3067347198871557 (12 / 35)\n",
            "train_acc: 0.3980222496909765, val_acc: 0.3497536945812808, train_loss: 1.3868695068713024, val_loss: 1.402725012431591 (13 / 35)\n",
            "train_acc: 0.4276885043263288, val_acc: 0.41379310344827586, train_loss: 1.3173313795120372, val_loss: 1.3293636861105858 (14 / 35)\n",
            "train_acc: 0.4103831891223733, val_acc: 0.43349753694581283, train_loss: 1.3258165881424515, val_loss: 1.2297851484397362 (15 / 35)\n",
            "train_acc: 0.41285537700865266, val_acc: 0.4039408866995074, train_loss: 1.317890340524492, val_loss: 1.3537449548984397 (16 / 35)\n",
            "train_acc: 0.4363411619283066, val_acc: 0.4236453201970443, train_loss: 1.2633063719505433, val_loss: 1.2779797104191897 (17 / 35)\n",
            "train_acc: 0.4635352286773795, val_acc: 0.4729064039408867, train_loss: 1.221674284917315, val_loss: 1.2122810256892238 (18 / 35)\n",
            "train_acc: 0.4622991347342398, val_acc: 0.4187192118226601, train_loss: 1.2729653464848976, val_loss: 1.2548466051740599 (19 / 35)\n",
            "train_acc: 0.4647713226205192, val_acc: 0.46798029556650245, train_loss: 1.204022017338662, val_loss: 1.2416861447794685 (20 / 35)\n",
            "train_acc: 0.5129789864029666, val_acc: 0.4236453201970443, train_loss: 1.1509113397232829, val_loss: 1.2344410008397595 (21 / 35)\n",
            "train_acc: 0.5587144622991347, val_acc: 0.4827586206896552, train_loss: 1.0849087818149288, val_loss: 1.1369734779367306 (22 / 35)\n",
            "train_acc: 0.5723114956736712, val_acc: 0.4975369458128079, train_loss: 1.0384434897024346, val_loss: 1.1106367416569751 (23 / 35)\n",
            "train_acc: 0.5908529048207664, val_acc: 0.4827586206896552, train_loss: 0.9984091200551527, val_loss: 1.0985411951694581 (24 / 35)\n",
            "train_acc: 0.5908529048207664, val_acc: 0.4876847290640394, train_loss: 0.987083595379616, val_loss: 1.0934455060019281 (25 / 35)\n",
            "train_acc: 0.5822002472187886, val_acc: 0.4876847290640394, train_loss: 0.9928815454723514, val_loss: 1.0865175383431571 (26 / 35)\n",
            "train_acc: 0.5945611866501854, val_acc: 0.4876847290640394, train_loss: 0.9555827139776628, val_loss: 1.0837723991553772 (27 / 35)\n",
            "train_acc: 0.6007416563658838, val_acc: 0.49261083743842365, train_loss: 0.955286411036667, val_loss: 1.0849437185108954 (28 / 35)\n",
            "train_acc: 0.6007416563658838, val_acc: 0.4827586206896552, train_loss: 0.9674207944657806, val_loss: 1.090242438128429 (29 / 35)\n",
            "train_acc: 0.5908529048207664, val_acc: 0.49261083743842365, train_loss: 0.9571324805688799, val_loss: 1.0791994362629105 (30 / 35)\n",
            "train_acc: 0.6242274412855378, val_acc: 0.5024630541871922, train_loss: 0.9448048873943805, val_loss: 1.0821466122942018 (31 / 35)\n",
            "train_acc: 0.5920889987639061, val_acc: 0.5073891625615764, train_loss: 0.9328995764034493, val_loss: 1.0794419831243054 (32 / 35)\n",
            "train_acc: 0.6328800988875154, val_acc: 0.4975369458128079, train_loss: 0.917833435004957, val_loss: 1.079166317220979 (33 / 35)\n",
            "train_acc: 0.6205191594561187, val_acc: 0.49261083743842365, train_loss: 0.9312858949190901, val_loss: 1.0789826544634815 (34 / 35)\n",
            "train_acc: 0.6402966625463535, val_acc: 0.4975369458128079, train_loss: 0.8964742352110788, val_loss: 1.0878861332174592 (35 / 35)\n",
            "lr 0.004038551874580517, batch 12, decay 0.00024010957050540167, gamma 0.016088536390075778, val accuracy 0.5073891625615764, val loss 1.0794419831243054 [3 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.7813585027039271, val_loss: 1.7563240158146824 (1 / 35)\n",
            "train_acc: 0.20642768850432633, val_acc: 0.30049261083743845, train_loss: 1.7460081014409201, val_loss: 1.7274332598512396 (2 / 35)\n",
            "train_acc: 0.2583436341161928, val_acc: 0.2019704433497537, train_loss: 1.7389107622823254, val_loss: 1.7602327046135964 (3 / 35)\n",
            "train_acc: 0.2867737948084054, val_acc: 0.35960591133004927, train_loss: 1.6788580508992463, val_loss: 1.5679490933277336 (4 / 35)\n",
            "train_acc: 0.21137206427688504, val_acc: 0.21182266009852216, train_loss: 1.7563813803959247, val_loss: 1.7447256460565652 (5 / 35)\n",
            "train_acc: 0.22620519159456118, val_acc: 0.22167487684729065, train_loss: 1.7541621179309557, val_loss: 1.7136098205162387 (6 / 35)\n",
            "train_acc: 0.23362175525339926, val_acc: 0.22167487684729065, train_loss: 1.709781523835379, val_loss: 1.7024534887868195 (7 / 35)\n",
            "train_acc: 0.31396786155747836, val_acc: 0.33497536945812806, train_loss: 1.6223760757811727, val_loss: 1.494070135313889 (8 / 35)\n",
            "train_acc: 0.2941903584672435, val_acc: 0.3251231527093596, train_loss: 1.5920437820467577, val_loss: 1.6988512336326937 (9 / 35)\n",
            "train_acc: 0.3337453646477132, val_acc: 0.3054187192118227, train_loss: 1.522382194533189, val_loss: 1.6927049631996107 (10 / 35)\n",
            "train_acc: 0.3535228677379481, val_acc: 0.3645320197044335, train_loss: 1.5105860280460126, val_loss: 1.3876031525616574 (11 / 35)\n",
            "train_acc: 0.3547589616810878, val_acc: 0.32019704433497537, train_loss: 1.4816197162800284, val_loss: 1.400275103270714 (12 / 35)\n",
            "train_acc: 0.34363411619283063, val_acc: 0.33497536945812806, train_loss: 1.4248977274770938, val_loss: 1.3599773980126593 (13 / 35)\n",
            "train_acc: 0.3757725587144623, val_acc: 0.4088669950738916, train_loss: 1.4413662295701035, val_loss: 1.354823926986732 (14 / 35)\n",
            "train_acc: 0.3831891223733004, val_acc: 0.4039408866995074, train_loss: 1.3799872918535665, val_loss: 1.381907935653414 (15 / 35)\n",
            "train_acc: 0.3930778739184178, val_acc: 0.4088669950738916, train_loss: 1.3813444359782894, val_loss: 1.3464442976002622 (16 / 35)\n",
            "train_acc: 0.3943139678615575, val_acc: 0.43349753694581283, train_loss: 1.3771303750675894, val_loss: 1.2930264235130084 (17 / 35)\n",
            "train_acc: 0.4326328800988875, val_acc: 0.45320197044334976, train_loss: 1.301336153181286, val_loss: 1.277239973615543 (18 / 35)\n",
            "train_acc: 0.4758961681087763, val_acc: 0.4187192118226601, train_loss: 1.2497339661984863, val_loss: 1.2020986676216125 (19 / 35)\n",
            "train_acc: 0.4796044499381953, val_acc: 0.43842364532019706, train_loss: 1.2517588089953542, val_loss: 1.2004026374206167 (20 / 35)\n",
            "train_acc: 0.4894932014833127, val_acc: 0.4729064039408867, train_loss: 1.1786349403254033, val_loss: 1.1695662572466095 (21 / 35)\n",
            "train_acc: 0.5216316440049443, val_acc: 0.46798029556650245, train_loss: 1.1000407338879163, val_loss: 1.1491495247544914 (22 / 35)\n",
            "train_acc: 0.5673671199011124, val_acc: 0.458128078817734, train_loss: 1.0579096590190646, val_loss: 1.1199347611718578 (23 / 35)\n",
            "train_acc: 0.5624227441285538, val_acc: 0.46798029556650245, train_loss: 1.051015780646957, val_loss: 1.1260921513212139 (24 / 35)\n",
            "train_acc: 0.5661310259579728, val_acc: 0.4630541871921182, train_loss: 1.0579502534660037, val_loss: 1.1184431362915508 (25 / 35)\n",
            "train_acc: 0.5673671199011124, val_acc: 0.47783251231527096, train_loss: 1.0455802924406101, val_loss: 1.1178725752337226 (26 / 35)\n",
            "train_acc: 0.553770086526576, val_acc: 0.4729064039408867, train_loss: 1.0588787778641002, val_loss: 1.1165915235803632 (27 / 35)\n",
            "train_acc: 0.5673671199011124, val_acc: 0.47783251231527096, train_loss: 1.0314655966310773, val_loss: 1.1147028225396067 (28 / 35)\n",
            "train_acc: 0.546353522867738, val_acc: 0.4975369458128079, train_loss: 1.0315335184446224, val_loss: 1.1257490495155598 (29 / 35)\n",
            "train_acc: 0.5871446229913473, val_acc: 0.4876847290640394, train_loss: 1.0181443455487453, val_loss: 1.1257411099126187 (30 / 35)\n",
            "train_acc: 0.5624227441285538, val_acc: 0.49261083743842365, train_loss: 1.0223070708723976, val_loss: 1.1051338775991806 (31 / 35)\n",
            "train_acc: 0.5822002472187886, val_acc: 0.4827586206896552, train_loss: 1.0075156199475301, val_loss: 1.111583941235331 (32 / 35)\n",
            "train_acc: 0.5995055624227441, val_acc: 0.4975369458128079, train_loss: 0.9797030922361594, val_loss: 1.0968200344170256 (33 / 35)\n",
            "train_acc: 0.588380716934487, val_acc: 0.4876847290640394, train_loss: 1.0152381746966406, val_loss: 1.1081405487553826 (34 / 35)\n",
            "train_acc: 0.5735475896168108, val_acc: 0.4975369458128079, train_loss: 0.9980405246371539, val_loss: 1.1193869680606674 (35 / 35)\n",
            "lr 0.0042237987628595194, batch 15, decay 0.00042683917479004744, gamma 0.031192333743237592, val accuracy 0.4975369458128079, val loss 1.1257490495155598 [4 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.18912237330037082, val_acc: 0.1921182266009852, train_loss: 1.7782927997622118, val_loss: 1.7591932589197394 (1 / 35)\n",
            "train_acc: 0.21878862793572312, val_acc: 0.19704433497536947, train_loss: 1.764888536355404, val_loss: 1.7326638786663562 (2 / 35)\n",
            "train_acc: 0.23362175525339926, val_acc: 0.32019704433497537, train_loss: 1.7011883694987067, val_loss: 1.5855474454428762 (3 / 35)\n",
            "train_acc: 0.27812113720642767, val_acc: 0.3448275862068966, train_loss: 1.6650880498556035, val_loss: 1.6015953753382115 (4 / 35)\n",
            "train_acc: 0.33127317676143386, val_acc: 0.3448275862068966, train_loss: 1.5864642753883993, val_loss: 1.5273066594682891 (5 / 35)\n",
            "train_acc: 0.3226205191594561, val_acc: 0.3497536945812808, train_loss: 1.6065929532787855, val_loss: 1.5429617084305862 (6 / 35)\n",
            "train_acc: 0.3238566131025958, val_acc: 0.3399014778325123, train_loss: 1.5534617728444349, val_loss: 1.746960131552419 (7 / 35)\n",
            "train_acc: 0.3176761433868974, val_acc: 0.2857142857142857, train_loss: 1.5835197561308834, val_loss: 1.634410598595154 (8 / 35)\n",
            "train_acc: 0.35970333745364647, val_acc: 0.37438423645320196, train_loss: 1.4977778897739311, val_loss: 1.4883260665268734 (9 / 35)\n",
            "train_acc: 0.3757725587144623, val_acc: 0.3497536945812808, train_loss: 1.4146581534549538, val_loss: 1.3572034794708778 (10 / 35)\n",
            "train_acc: 0.4177997527812114, val_acc: 0.39901477832512317, train_loss: 1.3532472713326642, val_loss: 1.2954320155928287 (11 / 35)\n",
            "train_acc: 0.39555006180469715, val_acc: 0.4088669950738916, train_loss: 1.3685078768264525, val_loss: 1.3522927828610236 (12 / 35)\n",
            "train_acc: 0.4103831891223733, val_acc: 0.45320197044334976, train_loss: 1.3086729141042024, val_loss: 1.276670027836203 (13 / 35)\n",
            "train_acc: 0.4622991347342398, val_acc: 0.47783251231527096, train_loss: 1.263232729122577, val_loss: 1.3495704625627678 (14 / 35)\n",
            "train_acc: 0.4400494437577256, val_acc: 0.43349753694581283, train_loss: 1.2753808432073321, val_loss: 1.2257954034899257 (15 / 35)\n",
            "train_acc: 0.4561186650185414, val_acc: 0.4729064039408867, train_loss: 1.2909379456335004, val_loss: 1.1669913959033384 (16 / 35)\n",
            "train_acc: 0.49938195302843014, val_acc: 0.4729064039408867, train_loss: 1.1457669540447712, val_loss: 1.192607908119709 (17 / 35)\n",
            "train_acc: 0.4932014833127318, val_acc: 0.5517241379310345, train_loss: 1.176971461333804, val_loss: 1.074009899728991 (18 / 35)\n",
            "train_acc: 0.5500618046971569, val_acc: 0.47783251231527096, train_loss: 1.0733089855191733, val_loss: 1.3213121870468403 (19 / 35)\n",
            "train_acc: 0.5587144622991347, val_acc: 0.4975369458128079, train_loss: 1.0790786682012201, val_loss: 1.1953439988526218 (20 / 35)\n",
            "train_acc: 0.5970333745364648, val_acc: 0.5320197044334976, train_loss: 0.9738532080785895, val_loss: 1.157695013607664 (21 / 35)\n",
            "train_acc: 0.5673671199011124, val_acc: 0.5467980295566502, train_loss: 1.0038948083395423, val_loss: 1.0162087145990926 (22 / 35)\n",
            "train_acc: 0.6378244746600742, val_acc: 0.5517241379310345, train_loss: 0.8767687125760044, val_loss: 1.223518119069743 (23 / 35)\n",
            "train_acc: 0.6613102595797281, val_acc: 0.6108374384236454, train_loss: 0.8223182224520057, val_loss: 0.9733363880312501 (24 / 35)\n",
            "train_acc: 0.7070457354758962, val_acc: 0.5172413793103449, train_loss: 0.7544357309530043, val_loss: 1.2957371399907642 (25 / 35)\n",
            "train_acc: 0.715698393077874, val_acc: 0.49261083743842365, train_loss: 0.7561901041729047, val_loss: 1.439497168134586 (26 / 35)\n",
            "train_acc: 0.723114956736712, val_acc: 0.5073891625615764, train_loss: 0.7114892152905906, val_loss: 1.4874469223868083 (27 / 35)\n",
            "train_acc: 0.7416563658838071, val_acc: 0.5024630541871922, train_loss: 0.6294794336458661, val_loss: 1.5114262749996092 (28 / 35)\n",
            "train_acc: 0.7663782447466008, val_acc: 0.5566502463054187, train_loss: 0.5868667339438708, val_loss: 1.2197190186953897 (29 / 35)\n",
            "train_acc: 0.8034610630407911, val_acc: 0.5467980295566502, train_loss: 0.520784446847601, val_loss: 1.5236440253962438 (30 / 35)\n",
            "train_acc: 0.8108776266996292, val_acc: 0.5566502463054187, train_loss: 0.5250764113237301, val_loss: 1.4113283910481214 (31 / 35)\n",
            "train_acc: 0.8417799752781211, val_acc: 0.541871921182266, train_loss: 0.40269944110450107, val_loss: 2.100176135747891 (32 / 35)\n",
            "train_acc: 0.8380716934487021, val_acc: 0.5714285714285714, train_loss: 0.45722704227871, val_loss: 1.6193328209111255 (33 / 35)\n",
            "train_acc: 0.865265760197775, val_acc: 0.5172413793103449, train_loss: 0.3650682800540376, val_loss: 2.6902276227626896 (34 / 35)\n",
            "train_acc: 0.8059332509270705, val_acc: 0.5862068965517241, train_loss: 0.5110527146032037, val_loss: 1.397288083883342 (35 / 35)\n",
            "lr 0.004189400775885228, batch 10, decay 0.00010163296545678008, gamma 0.867020722584907, val accuracy 0.6108374384236454, val loss 0.9733363880312501 [5 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.1903584672435105, val_acc: 0.2512315270935961, train_loss: 1.7829452411206013, val_loss: 1.763297106832119 (1 / 35)\n",
            "train_acc: 0.20519159456118666, val_acc: 0.18226600985221675, train_loss: 1.7627744098528944, val_loss: 1.7402000157116668 (2 / 35)\n",
            "train_acc: 0.22620519159456118, val_acc: 0.35467980295566504, train_loss: 1.7415383308573322, val_loss: 1.7057915056867552 (3 / 35)\n",
            "train_acc: 0.2880098887515451, val_acc: 0.2315270935960591, train_loss: 1.6764177850209296, val_loss: 1.7675595656404355 (4 / 35)\n",
            "train_acc: 0.29913473423980225, val_acc: 0.2955665024630542, train_loss: 1.648133249748475, val_loss: 1.6543967292226593 (5 / 35)\n",
            "train_acc: 0.31396786155747836, val_acc: 0.3054187192118227, train_loss: 1.5726994806520724, val_loss: 1.5371520705704618 (6 / 35)\n",
            "train_acc: 0.34610630407911, val_acc: 0.39408866995073893, train_loss: 1.5832011894183635, val_loss: 1.4865828027278918 (7 / 35)\n",
            "train_acc: 0.311495673671199, val_acc: 0.3103448275862069, train_loss: 1.6104984013789663, val_loss: 1.5585575329846348 (8 / 35)\n",
            "train_acc: 0.3374536464771323, val_acc: 0.35467980295566504, train_loss: 1.512822423051992, val_loss: 1.4672659333116316 (9 / 35)\n",
            "train_acc: 0.377008652657602, val_acc: 0.3645320197044335, train_loss: 1.4179231937795105, val_loss: 1.3704983329244436 (10 / 35)\n",
            "train_acc: 0.37330037082818296, val_acc: 0.4088669950738916, train_loss: 1.5017297854382263, val_loss: 1.3271967800967213 (11 / 35)\n",
            "train_acc: 0.3819530284301607, val_acc: 0.42857142857142855, train_loss: 1.4256686777502703, val_loss: 1.2879130919578627 (12 / 35)\n",
            "train_acc: 0.4363411619283066, val_acc: 0.3399014778325123, train_loss: 1.3775962011333744, val_loss: 1.3791363171755975 (13 / 35)\n",
            "train_acc: 0.37453646477132263, val_acc: 0.39901477832512317, train_loss: 1.3934164618974267, val_loss: 1.3369207722800118 (14 / 35)\n",
            "train_acc: 0.40667490729295425, val_acc: 0.4187192118226601, train_loss: 1.3300335910470582, val_loss: 1.2739211787731188 (15 / 35)\n",
            "train_acc: 0.44252163164400493, val_acc: 0.43349753694581283, train_loss: 1.300202596541241, val_loss: 1.23452613535773 (16 / 35)\n",
            "train_acc: 0.4437577255871446, val_acc: 0.43842364532019706, train_loss: 1.311495336230812, val_loss: 1.3222443611163812 (17 / 35)\n",
            "train_acc: 0.4264524103831891, val_acc: 0.43842364532019706, train_loss: 1.3233832457599004, val_loss: 1.2509075106658372 (18 / 35)\n",
            "train_acc: 0.4400494437577256, val_acc: 0.4630541871921182, train_loss: 1.2566731732766914, val_loss: 1.1900387620691009 (19 / 35)\n",
            "train_acc: 0.4252163164400494, val_acc: 0.46798029556650245, train_loss: 1.2525141796900698, val_loss: 1.2539047877776799 (20 / 35)\n",
            "train_acc: 0.4635352286773795, val_acc: 0.4876847290640394, train_loss: 1.231956002223035, val_loss: 1.1385348809176479 (21 / 35)\n",
            "train_acc: 0.5364647713226205, val_acc: 0.4975369458128079, train_loss: 1.1250023035832182, val_loss: 1.1806237330577645 (22 / 35)\n",
            "train_acc: 0.5512978986402967, val_acc: 0.5024630541871922, train_loss: 1.090292848158531, val_loss: 1.113583680737782 (23 / 35)\n",
            "train_acc: 0.5525339925834364, val_acc: 0.4876847290640394, train_loss: 1.0855487711055316, val_loss: 1.1747858608003907 (24 / 35)\n",
            "train_acc: 0.5636588380716935, val_acc: 0.5221674876847291, train_loss: 1.0728763257911975, val_loss: 1.081966430682854 (25 / 35)\n",
            "train_acc: 0.5822002472187886, val_acc: 0.5172413793103449, train_loss: 1.0040332542361672, val_loss: 1.1156141564176587 (26 / 35)\n",
            "train_acc: 0.595797280593325, val_acc: 0.5123152709359606, train_loss: 0.9787440523597307, val_loss: 1.0918002240176272 (27 / 35)\n",
            "train_acc: 0.6007416563658838, val_acc: 0.4975369458128079, train_loss: 0.990268266760964, val_loss: 1.1899239642573107 (28 / 35)\n",
            "train_acc: 0.6205191594561187, val_acc: 0.5467980295566502, train_loss: 0.9599608484245791, val_loss: 1.0305330312898007 (29 / 35)\n",
            "train_acc: 0.6291718170580964, val_acc: 0.5517241379310345, train_loss: 0.9210277954933818, val_loss: 1.0267447030603005 (30 / 35)\n",
            "train_acc: 0.6143386897404203, val_acc: 0.5172413793103449, train_loss: 0.9649401038185186, val_loss: 1.1133585394603278 (31 / 35)\n",
            "train_acc: 0.6402966625463535, val_acc: 0.5172413793103449, train_loss: 0.8870585533169792, val_loss: 1.138330170893904 (32 / 35)\n",
            "train_acc: 0.6168108776266996, val_acc: 0.5665024630541872, train_loss: 0.869930945088159, val_loss: 1.0141521610062698 (33 / 35)\n",
            "train_acc: 0.6711990111248455, val_acc: 0.5467980295566502, train_loss: 0.8387340850234768, val_loss: 1.15184840259 (34 / 35)\n",
            "train_acc: 0.7008652657601978, val_acc: 0.5714285714285714, train_loss: 0.7875853433228835, val_loss: 1.0816205089609023 (35 / 35)\n",
            "lr 0.0019921626228324653, batch 13, decay 1.662468058989626e-06, gamma 0.342088312815491, val accuracy 0.5714285714285714, val loss 1.0816205089609023 [6 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.1681087762669963, val_acc: 0.21182266009852216, train_loss: 1.775088109103652, val_loss: 1.753412405845567 (1 / 35)\n",
            "train_acc: 0.19777503090234858, val_acc: 0.22167487684729065, train_loss: 1.7638309309892217, val_loss: 1.7331564949063831 (2 / 35)\n",
            "train_acc: 0.25092707045735474, val_acc: 0.18719211822660098, train_loss: 1.699836265318768, val_loss: 1.7748292379191357 (3 / 35)\n",
            "train_acc: 0.22867737948084055, val_acc: 0.20689655172413793, train_loss: 1.7548576966204366, val_loss: 1.7137495561186316 (4 / 35)\n",
            "train_acc: 0.2904820766378245, val_acc: 0.3054187192118227, train_loss: 1.691244036217113, val_loss: 1.5569172005348018 (5 / 35)\n",
            "train_acc: 0.3288009888751545, val_acc: 0.3054187192118227, train_loss: 1.6086610038436682, val_loss: 1.549316883674396 (6 / 35)\n",
            "train_acc: 0.33250927070457353, val_acc: 0.2561576354679803, train_loss: 1.5122009534918333, val_loss: 1.7940487321374452 (7 / 35)\n",
            "train_acc: 0.32509270704573545, val_acc: 0.32019704433497537, train_loss: 1.537063990888843, val_loss: 1.4285990898245073 (8 / 35)\n",
            "train_acc: 0.3362175525339926, val_acc: 0.37438423645320196, train_loss: 1.4472307899531682, val_loss: 1.380091325402847 (9 / 35)\n",
            "train_acc: 0.3757725587144623, val_acc: 0.3054187192118227, train_loss: 1.4280988807583916, val_loss: 1.6691012511699659 (10 / 35)\n",
            "train_acc: 0.3658838071693449, val_acc: 0.4187192118226601, train_loss: 1.4227017153915575, val_loss: 1.2785000765852153 (11 / 35)\n",
            "train_acc: 0.4215080346106304, val_acc: 0.3891625615763547, train_loss: 1.3218343873843275, val_loss: 1.457481889889158 (12 / 35)\n",
            "train_acc: 0.40296662546353523, val_acc: 0.4236453201970443, train_loss: 1.372006969781977, val_loss: 1.2974853732903016 (13 / 35)\n",
            "train_acc: 0.4054388133498146, val_acc: 0.3842364532019704, train_loss: 1.3602406857776996, val_loss: 1.3414869044214635 (14 / 35)\n",
            "train_acc: 0.4400494437577256, val_acc: 0.42857142857142855, train_loss: 1.252904897567221, val_loss: 1.2762779784320024 (15 / 35)\n",
            "train_acc: 0.4622991347342398, val_acc: 0.4482758620689655, train_loss: 1.262585673550298, val_loss: 1.2055598923138209 (16 / 35)\n",
            "train_acc: 0.45241038318912236, val_acc: 0.458128078817734, train_loss: 1.2388638467222857, val_loss: 1.2256670456214491 (17 / 35)\n",
            "train_acc: 0.4894932014833127, val_acc: 0.458128078817734, train_loss: 1.1921869535528684, val_loss: 1.2423155166832685 (18 / 35)\n",
            "train_acc: 0.5080346106304079, val_acc: 0.458128078817734, train_loss: 1.147345401742697, val_loss: 1.2796426623912867 (19 / 35)\n",
            "train_acc: 0.5203955500618047, val_acc: 0.5073891625615764, train_loss: 1.1373282435208523, val_loss: 1.1762601242864072 (20 / 35)\n",
            "train_acc: 0.5587144622991347, val_acc: 0.3448275862068966, train_loss: 1.0293337989354459, val_loss: 1.6982061252218161 (21 / 35)\n",
            "train_acc: 0.6588380716934487, val_acc: 0.4975369458128079, train_loss: 0.8636062696336668, val_loss: 1.1931791734225645 (22 / 35)\n",
            "train_acc: 0.6996291718170581, val_acc: 0.5270935960591133, train_loss: 0.7630448809954969, val_loss: 1.1365692210314897 (23 / 35)\n",
            "train_acc: 0.7008652657601978, val_acc: 0.5517241379310345, train_loss: 0.7287297496394852, val_loss: 1.149295200561655 (24 / 35)\n",
            "train_acc: 0.7243510506798516, val_acc: 0.5270935960591133, train_loss: 0.6767687432108762, val_loss: 1.1678240305097232 (25 / 35)\n",
            "train_acc: 0.7503090234857849, val_acc: 0.5517241379310345, train_loss: 0.6472940527464462, val_loss: 1.1786103683152223 (26 / 35)\n",
            "train_acc: 0.7527812113720643, val_acc: 0.541871921182266, train_loss: 0.6187858459239247, val_loss: 1.2078671713767968 (27 / 35)\n",
            "train_acc: 0.7700865265760197, val_acc: 0.5665024630541872, train_loss: 0.5885912564540529, val_loss: 1.1847642927334225 (28 / 35)\n",
            "train_acc: 0.8034610630407911, val_acc: 0.5615763546798029, train_loss: 0.5177139400404375, val_loss: 1.3405331420193751 (29 / 35)\n",
            "train_acc: 0.8084054388133498, val_acc: 0.5763546798029556, train_loss: 0.5007249186153907, val_loss: 1.2566691214227912 (30 / 35)\n",
            "train_acc: 0.799752781211372, val_acc: 0.6009852216748769, train_loss: 0.5152063125143534, val_loss: 1.2801211978414375 (31 / 35)\n",
            "train_acc: 0.8071693448702101, val_acc: 0.6009852216748769, train_loss: 0.47329392244553536, val_loss: 1.2884564986957119 (32 / 35)\n",
            "train_acc: 0.8454882571075402, val_acc: 0.5862068965517241, train_loss: 0.4229863943953449, val_loss: 1.5056029293924718 (33 / 35)\n",
            "train_acc: 0.8479604449938195, val_acc: 0.5862068965517241, train_loss: 0.40157806829115367, val_loss: 1.4207099130000975 (34 / 35)\n",
            "train_acc: 0.8603213844252163, val_acc: 0.5960591133004927, train_loss: 0.3707203178382185, val_loss: 1.4292544872302728 (35 / 35)\n",
            "lr 0.002769949085723339, batch 8, decay 0.00011447095044880037, gamma 0.09277641094378263, val accuracy 0.6009852216748769, val loss 1.2801211978414375 [7 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.16069221260815822, val_acc: 0.18226600985221675, train_loss: 1.7774352043019825, val_loss: 1.7563627582465486 (1 / 35)\n",
            "train_acc: 0.21631644004944375, val_acc: 0.18226600985221675, train_loss: 1.738082394464349, val_loss: 1.7710922316377387 (2 / 35)\n",
            "train_acc: 0.2595797280593325, val_acc: 0.2561576354679803, train_loss: 1.6692724168963722, val_loss: 1.7227710285797495 (3 / 35)\n",
            "train_acc: 0.20519159456118666, val_acc: 0.21182266009852216, train_loss: 1.7682119641816807, val_loss: 1.7294712636271135 (4 / 35)\n",
            "train_acc: 0.21137206427688504, val_acc: 0.2413793103448276, train_loss: 1.7583788338638795, val_loss: 1.7097577455595796 (5 / 35)\n",
            "train_acc: 0.24969097651421507, val_acc: 0.2660098522167488, train_loss: 1.7071011200528798, val_loss: 1.6614492585506346 (6 / 35)\n",
            "train_acc: 0.27935723114956734, val_acc: 0.270935960591133, train_loss: 1.6718877886959589, val_loss: 1.6789877191552975 (7 / 35)\n",
            "train_acc: 0.33250927070457353, val_acc: 0.35467980295566504, train_loss: 1.5720450736683584, val_loss: 1.5079294079043009 (8 / 35)\n",
            "train_acc: 0.35599505562422745, val_acc: 0.33004926108374383, train_loss: 1.521399873590882, val_loss: 1.4814303185552211 (9 / 35)\n",
            "train_acc: 0.3621755253399258, val_acc: 0.3842364532019704, train_loss: 1.487493130126312, val_loss: 1.432254589837173 (10 / 35)\n",
            "train_acc: 0.36711990111248455, val_acc: 0.39408866995073893, train_loss: 1.4177656668815095, val_loss: 1.404390582310155 (11 / 35)\n",
            "train_acc: 0.39555006180469715, val_acc: 0.41379310344827586, train_loss: 1.3951420445082656, val_loss: 1.4053271368806586 (12 / 35)\n",
            "train_acc: 0.40914709517923364, val_acc: 0.39901477832512317, train_loss: 1.3745329164898734, val_loss: 1.3698088547279095 (13 / 35)\n",
            "train_acc: 0.44746600741656367, val_acc: 0.3103448275862069, train_loss: 1.295762135012925, val_loss: 1.653196808739836 (14 / 35)\n",
            "train_acc: 0.43139678615574784, val_acc: 0.3645320197044335, train_loss: 1.2925833830579987, val_loss: 1.3717694772875368 (15 / 35)\n",
            "train_acc: 0.4907292954264524, val_acc: 0.39901477832512317, train_loss: 1.2196413645490876, val_loss: 1.384580725225909 (16 / 35)\n",
            "train_acc: 0.5142150803461063, val_acc: 0.45320197044334976, train_loss: 1.150225514387171, val_loss: 1.3552140244122208 (17 / 35)\n",
            "train_acc: 0.5327564894932015, val_acc: 0.4039408866995074, train_loss: 1.1339430411165519, val_loss: 1.3565100754423094 (18 / 35)\n",
            "train_acc: 0.5908529048207664, val_acc: 0.4433497536945813, train_loss: 1.030558724927961, val_loss: 1.4810550261307232 (19 / 35)\n",
            "train_acc: 0.6291718170580964, val_acc: 0.4039408866995074, train_loss: 0.8971746457079874, val_loss: 1.7766964001021361 (20 / 35)\n",
            "train_acc: 0.6514215080346106, val_acc: 0.3645320197044335, train_loss: 0.8826779647280171, val_loss: 1.5053982722935417 (21 / 35)\n",
            "train_acc: 0.7898640296662547, val_acc: 0.4827586206896552, train_loss: 0.5835465318045598, val_loss: 1.4590294889628594 (22 / 35)\n",
            "train_acc: 0.8714462299134734, val_acc: 0.458128078817734, train_loss: 0.37379122237192536, val_loss: 1.5622944887635744 (23 / 35)\n",
            "train_acc: 0.9048207663782447, val_acc: 0.4876847290640394, train_loss: 0.27619838316744133, val_loss: 1.777060744797655 (24 / 35)\n",
            "train_acc: 0.92336217552534, val_acc: 0.5123152709359606, train_loss: 0.2180372159766915, val_loss: 1.8795782304162463 (25 / 35)\n",
            "train_acc: 0.9419035846724351, val_acc: 0.5024630541871922, train_loss: 0.15761975393307076, val_loss: 1.8952994936792722 (26 / 35)\n",
            "train_acc: 0.9740420271940667, val_acc: 0.5221674876847291, train_loss: 0.09803077655905404, val_loss: 2.3864782203007215 (27 / 35)\n",
            "train_acc: 0.9765142150803461, val_acc: 0.5369458128078818, train_loss: 0.08616552644665958, val_loss: 2.55171890505429 (28 / 35)\n",
            "train_acc: 0.9678615574783683, val_acc: 0.5221674876847291, train_loss: 0.10616114142503963, val_loss: 2.311634160908572 (29 / 35)\n",
            "train_acc: 0.9839307787391842, val_acc: 0.5270935960591133, train_loss: 0.07339102759202125, val_loss: 2.5725176310891587 (30 / 35)\n",
            "train_acc: 0.9740420271940667, val_acc: 0.5172413793103449, train_loss: 0.07002676255328694, val_loss: 2.2854453190206896 (31 / 35)\n",
            "train_acc: 0.9814585908529048, val_acc: 0.5517241379310345, train_loss: 0.052623165847344514, val_loss: 2.902159128870283 (32 / 35)\n",
            "train_acc: 0.9851668726823238, val_acc: 0.5073891625615764, train_loss: 0.05836838844827433, val_loss: 2.8830012159394514 (33 / 35)\n",
            "train_acc: 0.9938195302843016, val_acc: 0.5270935960591133, train_loss: 0.03385858188011443, val_loss: 2.919295038495745 (34 / 35)\n",
            "train_acc: 0.9901112484548825, val_acc: 0.5320197044334976, train_loss: 0.03333206111922105, val_loss: 2.7508338959933503 (35 / 35)\n",
            "lr 0.004505781266978887, batch 8, decay 3.7680671759241114e-05, gamma 0.13384037348449876, val accuracy 0.5517241379310345, val loss 2.902159128870283 [8 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.18046971569839307, val_acc: 0.18226600985221675, train_loss: 1.7777289720931366, val_loss: 1.759886389295456 (1 / 35)\n",
            "train_acc: 0.20395550061804696, val_acc: 0.18719211822660098, train_loss: 1.7640624920134196, val_loss: 1.7478779642452746 (2 / 35)\n",
            "train_acc: 0.2200247218788628, val_acc: 0.29064039408866993, train_loss: 1.7417277495557504, val_loss: 1.700667796463802 (3 / 35)\n",
            "train_acc: 0.3053152039555006, val_acc: 0.3793103448275862, train_loss: 1.6589095017818645, val_loss: 1.5359722105740325 (4 / 35)\n",
            "train_acc: 0.32014833127317677, val_acc: 0.3793103448275862, train_loss: 1.6037571717546366, val_loss: 1.492073650430576 (5 / 35)\n",
            "train_acc: 0.3362175525339926, val_acc: 0.39408866995073893, train_loss: 1.5380188598768378, val_loss: 1.377736015860083 (6 / 35)\n",
            "train_acc: 0.3374536464771323, val_acc: 0.3645320197044335, train_loss: 1.5275520367734365, val_loss: 1.4491975257549379 (7 / 35)\n",
            "train_acc: 0.3868974042027194, val_acc: 0.3891625615763547, train_loss: 1.447697677777341, val_loss: 1.3511543077201091 (8 / 35)\n",
            "train_acc: 0.3757725587144623, val_acc: 0.39901477832512317, train_loss: 1.3939310391842215, val_loss: 1.343105879616855 (9 / 35)\n",
            "train_acc: 0.3683559950556242, val_acc: 0.3793103448275862, train_loss: 1.3853663658476878, val_loss: 1.3807529337300455 (10 / 35)\n",
            "train_acc: 0.39184177997527814, val_acc: 0.3793103448275862, train_loss: 1.3734457635761634, val_loss: 1.261102474381771 (11 / 35)\n",
            "train_acc: 0.4289245982694685, val_acc: 0.45320197044334976, train_loss: 1.341609590575191, val_loss: 1.2445505939680954 (12 / 35)\n",
            "train_acc: 0.411619283065513, val_acc: 0.4482758620689655, train_loss: 1.3292553287059325, val_loss: 1.2747835998464687 (13 / 35)\n",
            "train_acc: 0.4622991347342398, val_acc: 0.43842364532019706, train_loss: 1.2678917408431563, val_loss: 1.2654647903489362 (14 / 35)\n",
            "train_acc: 0.4215080346106304, val_acc: 0.4433497536945813, train_loss: 1.3122761204599303, val_loss: 1.235061399161522 (15 / 35)\n",
            "train_acc: 0.4622991347342398, val_acc: 0.4236453201970443, train_loss: 1.2179687261876129, val_loss: 1.339995025413964 (16 / 35)\n",
            "train_acc: 0.47713226205191595, val_acc: 0.46798029556650245, train_loss: 1.181505857498301, val_loss: 1.2111038706572772 (17 / 35)\n",
            "train_acc: 0.511742892459827, val_acc: 0.46798029556650245, train_loss: 1.163525467897375, val_loss: 1.1542523752879628 (18 / 35)\n",
            "train_acc: 0.5241038318912238, val_acc: 0.4975369458128079, train_loss: 1.1313594887666265, val_loss: 1.141069413112302 (19 / 35)\n",
            "train_acc: 0.5327564894932015, val_acc: 0.5172413793103449, train_loss: 1.121046991740228, val_loss: 1.2028562696696503 (20 / 35)\n",
            "train_acc: 0.5451174289245982, val_acc: 0.5270935960591133, train_loss: 1.060566203113834, val_loss: 1.1485621826402073 (21 / 35)\n",
            "train_acc: 0.6291718170580964, val_acc: 0.5270935960591133, train_loss: 0.907656138405959, val_loss: 1.1624213198722877 (22 / 35)\n",
            "train_acc: 0.6477132262051916, val_acc: 0.5221674876847291, train_loss: 0.8549319254453162, val_loss: 1.0832253735640953 (23 / 35)\n",
            "train_acc: 0.6674907292954264, val_acc: 0.5320197044334976, train_loss: 0.8056370965924634, val_loss: 1.0581164775517187 (24 / 35)\n",
            "train_acc: 0.6711990111248455, val_acc: 0.5221674876847291, train_loss: 0.7929937090213572, val_loss: 1.1985975564113391 (25 / 35)\n",
            "train_acc: 0.6971569839307787, val_acc: 0.541871921182266, train_loss: 0.7427344072623955, val_loss: 1.1157158266734608 (26 / 35)\n",
            "train_acc: 0.7033374536464772, val_acc: 0.5517241379310345, train_loss: 0.7140486924845739, val_loss: 1.1564096592623612 (27 / 35)\n",
            "train_acc: 0.7280593325092707, val_acc: 0.5665024630541872, train_loss: 0.669510917846293, val_loss: 1.0684686116690707 (28 / 35)\n",
            "train_acc: 0.7354758961681088, val_acc: 0.5517241379310345, train_loss: 0.6549434600529181, val_loss: 1.1587972635118833 (29 / 35)\n",
            "train_acc: 0.7255871446229913, val_acc: 0.5812807881773399, train_loss: 0.6578556963407213, val_loss: 1.1249560076614906 (30 / 35)\n",
            "train_acc: 0.7787391841779975, val_acc: 0.5467980295566502, train_loss: 0.5711697551464415, val_loss: 1.2257172494686295 (31 / 35)\n",
            "train_acc: 0.7713226205191595, val_acc: 0.5714285714285714, train_loss: 0.5701093072870606, val_loss: 1.1950469974226552 (32 / 35)\n",
            "train_acc: 0.7564894932014833, val_acc: 0.5566502463054187, train_loss: 0.5753904275494836, val_loss: 1.2153446389536553 (33 / 35)\n",
            "train_acc: 0.7688504326328801, val_acc: 0.5862068965517241, train_loss: 0.5764595017444955, val_loss: 1.0978303556078173 (34 / 35)\n",
            "train_acc: 0.7948084054388134, val_acc: 0.5615763546798029, train_loss: 0.5230950245032794, val_loss: 1.4870188689877835 (35 / 35)\n",
            "lr 0.002977101119836985, batch 11, decay 4.150884120307582e-05, gamma 0.13388785635608252, val accuracy 0.5862068965517241, val loss 1.0978303556078173 [9 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.1792336217552534, val_acc: 0.18226600985221675, train_loss: 1.783722990375514, val_loss: 1.764444936085217 (1 / 35)\n",
            "train_acc: 0.20519159456118666, val_acc: 0.18226600985221675, train_loss: 1.747963473587602, val_loss: 1.7570637223755785 (2 / 35)\n",
            "train_acc: 0.21631644004944375, val_acc: 0.18226600985221675, train_loss: 1.7438685873382909, val_loss: 1.747198921119051 (3 / 35)\n",
            "train_acc: 0.27070457354758964, val_acc: 0.3399014778325123, train_loss: 1.6951605516252175, val_loss: 1.5710579614921156 (4 / 35)\n",
            "train_acc: 0.30778739184178, val_acc: 0.21674876847290642, train_loss: 1.6483755916246525, val_loss: 1.919127398523791 (5 / 35)\n",
            "train_acc: 0.32014833127317677, val_acc: 0.3645320197044335, train_loss: 1.608503840615045, val_loss: 1.4479244988540123 (6 / 35)\n",
            "train_acc: 0.33868974042027195, val_acc: 0.41379310344827586, train_loss: 1.520148241328368, val_loss: 1.3715711514938054 (7 / 35)\n",
            "train_acc: 0.3572311495673671, val_acc: 0.3251231527093596, train_loss: 1.5099773881461918, val_loss: 1.4103359348081015 (8 / 35)\n",
            "train_acc: 0.37453646477132263, val_acc: 0.35467980295566504, train_loss: 1.4405363242617348, val_loss: 1.5208500846853397 (9 / 35)\n",
            "train_acc: 0.36711990111248455, val_acc: 0.3054187192118227, train_loss: 1.415419070770773, val_loss: 1.4705473848164374 (10 / 35)\n",
            "train_acc: 0.35599505562422745, val_acc: 0.3694581280788177, train_loss: 1.4488970691105638, val_loss: 1.4238544661423256 (11 / 35)\n",
            "train_acc: 0.380716934487021, val_acc: 0.42857142857142855, train_loss: 1.3866783034226804, val_loss: 1.3481607842327925 (12 / 35)\n",
            "train_acc: 0.42027194066749074, val_acc: 0.4729064039408867, train_loss: 1.3451155372544183, val_loss: 1.2490838402010538 (13 / 35)\n",
            "train_acc: 0.40667490729295425, val_acc: 0.4236453201970443, train_loss: 1.3453229207485657, val_loss: 1.3063845734290889 (14 / 35)\n",
            "train_acc: 0.4400494437577256, val_acc: 0.43349753694581283, train_loss: 1.2993955081708646, val_loss: 1.2699194022000129 (15 / 35)\n",
            "train_acc: 0.4326328800988875, val_acc: 0.4630541871921182, train_loss: 1.2934255048872072, val_loss: 1.2277976139425644 (16 / 35)\n",
            "train_acc: 0.4561186650185414, val_acc: 0.4630541871921182, train_loss: 1.2762718362772862, val_loss: 1.233036385381163 (17 / 35)\n",
            "train_acc: 0.4610630407911001, val_acc: 0.4630541871921182, train_loss: 1.2472830937141541, val_loss: 1.2835186217806023 (18 / 35)\n",
            "train_acc: 0.4437577255871446, val_acc: 0.5024630541871922, train_loss: 1.304946999025286, val_loss: 1.1952551136463148 (19 / 35)\n",
            "train_acc: 0.48702101359703337, val_acc: 0.4482758620689655, train_loss: 1.2052636992356687, val_loss: 1.330090036533149 (20 / 35)\n",
            "train_acc: 0.48825710754017304, val_acc: 0.458128078817734, train_loss: 1.1956934330637288, val_loss: 1.1759917642095405 (21 / 35)\n",
            "train_acc: 0.5006180469715699, val_acc: 0.49261083743842365, train_loss: 1.1489119292484373, val_loss: 1.194458676676445 (22 / 35)\n",
            "train_acc: 0.511742892459827, val_acc: 0.4975369458128079, train_loss: 1.1070038597427576, val_loss: 1.1819156760652665 (23 / 35)\n",
            "train_acc: 0.5525339925834364, val_acc: 0.541871921182266, train_loss: 1.0729638112637552, val_loss: 1.1094482273891055 (24 / 35)\n",
            "train_acc: 0.5661310259579728, val_acc: 0.5172413793103449, train_loss: 1.0527097736801883, val_loss: 1.243190728972111 (25 / 35)\n",
            "train_acc: 0.5648949320148331, val_acc: 0.5123152709359606, train_loss: 1.0359333336574332, val_loss: 1.116585764685288 (26 / 35)\n",
            "train_acc: 0.6069221260815822, val_acc: 0.5320197044334976, train_loss: 0.954275896286935, val_loss: 1.081476121113218 (27 / 35)\n",
            "train_acc: 0.6279357231149567, val_acc: 0.5172413793103449, train_loss: 0.9283272971034198, val_loss: 1.2281454534366214 (28 / 35)\n",
            "train_acc: 0.6180469715698393, val_acc: 0.5566502463054187, train_loss: 0.9719327409718328, val_loss: 1.0998677452796786 (29 / 35)\n",
            "train_acc: 0.65389369592089, val_acc: 0.5714285714285714, train_loss: 0.8592370190048689, val_loss: 1.090796104205653 (30 / 35)\n",
            "train_acc: 0.6662546353522868, val_acc: 0.5714285714285714, train_loss: 0.852346097583087, val_loss: 1.086410992251241 (31 / 35)\n",
            "train_acc: 0.6897404202719407, val_acc: 0.5763546798029556, train_loss: 0.7817242566970429, val_loss: 0.950794367073792 (32 / 35)\n",
            "train_acc: 0.69221260815822, val_acc: 0.5763546798029556, train_loss: 0.7927190936245346, val_loss: 1.1491598419367974 (33 / 35)\n",
            "train_acc: 0.7095179233621756, val_acc: 0.5221674876847291, train_loss: 0.735212870669748, val_loss: 1.485970807192948 (34 / 35)\n",
            "train_acc: 0.7367119901112484, val_acc: 0.5763546798029556, train_loss: 0.6770164825123527, val_loss: 1.009009408319525 (35 / 35)\n",
            "lr 0.0011772079063449023, batch 8, decay 0.000809601695815408, gamma 0.6494556876110809, val accuracy 0.5763546798029556, val loss 0.950794367073792 [10 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.17181705809641531, val_acc: 0.18226600985221675, train_loss: 1.7730902337615364, val_loss: 1.746286363437258 (1 / 35)\n",
            "train_acc: 0.2138442521631644, val_acc: 0.27586206896551724, train_loss: 1.739457838467526, val_loss: 1.7289673336620988 (2 / 35)\n",
            "train_acc: 0.2941903584672435, val_acc: 0.2413793103448276, train_loss: 1.6499318345662837, val_loss: 1.8279977571494475 (3 / 35)\n",
            "train_acc: 0.3065512978986403, val_acc: 0.28078817733990147, train_loss: 1.6184794787865486, val_loss: 1.6961555886151167 (4 / 35)\n",
            "train_acc: 0.315203955500618, val_acc: 0.24630541871921183, train_loss: 1.6111235264941994, val_loss: 1.759165776186976 (5 / 35)\n",
            "train_acc: 0.27935723114956734, val_acc: 0.2512315270935961, train_loss: 1.659845726009647, val_loss: 1.7036204619947912 (6 / 35)\n",
            "train_acc: 0.32014833127317677, val_acc: 0.2660098522167488, train_loss: 1.5704509573902277, val_loss: 1.7390686495257128 (7 / 35)\n",
            "train_acc: 0.31396786155747836, val_acc: 0.3645320197044335, train_loss: 1.585432004132878, val_loss: 1.3719806069223752 (8 / 35)\n",
            "train_acc: 0.35599505562422745, val_acc: 0.39408866995073893, train_loss: 1.4432223662457744, val_loss: 1.3758706529739455 (9 / 35)\n",
            "train_acc: 0.37453646477132263, val_acc: 0.4187192118226601, train_loss: 1.4285648629456131, val_loss: 1.3300027430351145 (10 / 35)\n",
            "train_acc: 0.41903584672435107, val_acc: 0.4088669950738916, train_loss: 1.3630853627609234, val_loss: 1.3163885726717306 (11 / 35)\n",
            "train_acc: 0.380716934487021, val_acc: 0.4039408866995074, train_loss: 1.405480369059795, val_loss: 1.3122904758735243 (12 / 35)\n",
            "train_acc: 0.4326328800988875, val_acc: 0.4630541871921182, train_loss: 1.314797665560054, val_loss: 1.2349614421722337 (13 / 35)\n",
            "train_acc: 0.4363411619283066, val_acc: 0.4482758620689655, train_loss: 1.2820840617929607, val_loss: 1.2429259416505034 (14 / 35)\n",
            "train_acc: 0.4289245982694685, val_acc: 0.4482758620689655, train_loss: 1.251398192274261, val_loss: 1.3473532888396034 (15 / 35)\n",
            "train_acc: 0.4796044499381953, val_acc: 0.4975369458128079, train_loss: 1.2035924126250193, val_loss: 1.1860004757425469 (16 / 35)\n",
            "train_acc: 0.519159456118665, val_acc: 0.49261083743842365, train_loss: 1.168804095834678, val_loss: 1.4498757449864166 (17 / 35)\n",
            "train_acc: 0.5315203955500618, val_acc: 0.5221674876847291, train_loss: 1.1326922178268433, val_loss: 1.2681057180089903 (18 / 35)\n",
            "train_acc: 0.5203955500618047, val_acc: 0.49261083743842365, train_loss: 1.1220547767593185, val_loss: 1.3019797164084288 (19 / 35)\n",
            "train_acc: 0.5871446229913473, val_acc: 0.541871921182266, train_loss: 0.9813052085775086, val_loss: 1.284005668803389 (20 / 35)\n",
            "train_acc: 0.6081582200247219, val_acc: 0.4975369458128079, train_loss: 0.9543679510191433, val_loss: 1.1406841407268506 (21 / 35)\n",
            "train_acc: 0.6588380716934487, val_acc: 0.5517241379310345, train_loss: 0.8103429042217316, val_loss: 1.0905149849911628 (22 / 35)\n",
            "train_acc: 0.7021013597033374, val_acc: 0.541871921182266, train_loss: 0.7573872618054872, val_loss: 1.2000866295962498 (23 / 35)\n",
            "train_acc: 0.7243510506798516, val_acc: 0.5024630541871922, train_loss: 0.6812270717656215, val_loss: 1.5309180884525693 (24 / 35)\n",
            "train_acc: 0.7515451174289246, val_acc: 0.5467980295566502, train_loss: 0.6058312073736757, val_loss: 1.22282400463015 (25 / 35)\n",
            "train_acc: 0.757725587144623, val_acc: 0.6108374384236454, train_loss: 0.563677055026751, val_loss: 1.3896605913421791 (26 / 35)\n",
            "train_acc: 0.7799752781211372, val_acc: 0.541871921182266, train_loss: 0.5564562559533031, val_loss: 1.6261730715265414 (27 / 35)\n",
            "train_acc: 0.7725587144622992, val_acc: 0.5812807881773399, train_loss: 0.536017076129598, val_loss: 2.0548902094969757 (28 / 35)\n",
            "train_acc: 0.7849196538936959, val_acc: 0.5960591133004927, train_loss: 0.5318110604829193, val_loss: 1.3678953465569783 (29 / 35)\n",
            "train_acc: 0.8145859085290482, val_acc: 0.5960591133004927, train_loss: 0.46746133482463575, val_loss: 1.5416578974923476 (30 / 35)\n",
            "train_acc: 0.8590852904820766, val_acc: 0.5911330049261084, train_loss: 0.3458995374313317, val_loss: 1.8177106215301992 (31 / 35)\n",
            "train_acc: 0.8899876390605687, val_acc: 0.5123152709359606, train_loss: 0.33204408265806834, val_loss: 1.6627048343933861 (32 / 35)\n",
            "train_acc: 0.8368355995055624, val_acc: 0.5369458128078818, train_loss: 0.4399317605432459, val_loss: 1.9893337422110178 (33 / 35)\n",
            "train_acc: 0.8702101359703337, val_acc: 0.5812807881773399, train_loss: 0.3215132925995569, val_loss: 1.8747549126007286 (34 / 35)\n",
            "train_acc: 0.899876390605686, val_acc: 0.6206896551724138, train_loss: 0.29802447748376226, val_loss: 1.605207937251171 (35 / 35)\n",
            "lr 0.004593548898918902, batch 11, decay 0.00011682260793565572, gamma 0.6092083519476216, val accuracy 0.6206896551724138, val loss 1.605207937251171 [11 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.18541409147095178, val_acc: 0.18226600985221675, train_loss: 1.7756793949895795, val_loss: 1.7480084649447738 (1 / 35)\n",
            "train_acc: 0.21013597033374537, val_acc: 0.30049261083743845, train_loss: 1.748150199099141, val_loss: 1.703658757538631 (2 / 35)\n",
            "train_acc: 0.3003708281829419, val_acc: 0.33497536945812806, train_loss: 1.6645109033113061, val_loss: 1.6011636914878056 (3 / 35)\n",
            "train_acc: 0.29666254635352285, val_acc: 0.35467980295566504, train_loss: 1.628960478438435, val_loss: 1.5147459219241965 (4 / 35)\n",
            "train_acc: 0.3176761433868974, val_acc: 0.3251231527093596, train_loss: 1.6055201810723625, val_loss: 1.4967409536756318 (5 / 35)\n",
            "train_acc: 0.3337453646477132, val_acc: 0.33004926108374383, train_loss: 1.5201023111237288, val_loss: 1.4583559817281262 (6 / 35)\n",
            "train_acc: 0.35599505562422745, val_acc: 0.4187192118226601, train_loss: 1.4569443252089587, val_loss: 1.341003315202121 (7 / 35)\n",
            "train_acc: 0.3584672435105068, val_acc: 0.4088669950738916, train_loss: 1.4238003585188292, val_loss: 1.3405479583246955 (8 / 35)\n",
            "train_acc: 0.3621755253399258, val_acc: 0.3399014778325123, train_loss: 1.46917311797478, val_loss: 1.4704624928277115 (9 / 35)\n",
            "train_acc: 0.38442521631644005, val_acc: 0.3793103448275862, train_loss: 1.3724058285926564, val_loss: 1.5240618565986896 (10 / 35)\n",
            "train_acc: 0.3992583436341162, val_acc: 0.4039408866995074, train_loss: 1.3464578950066206, val_loss: 1.2974876617563182 (11 / 35)\n",
            "train_acc: 0.43757725587144625, val_acc: 0.4187192118226601, train_loss: 1.2853584993902332, val_loss: 1.2293622534850548 (12 / 35)\n",
            "train_acc: 0.4276885043263288, val_acc: 0.4729064039408867, train_loss: 1.2871062496241887, val_loss: 1.1817575097084045 (13 / 35)\n",
            "train_acc: 0.46600741656365885, val_acc: 0.46798029556650245, train_loss: 1.2519217532114282, val_loss: 1.1868019062897255 (14 / 35)\n",
            "train_acc: 0.4796044499381953, val_acc: 0.41379310344827586, train_loss: 1.2120543025774773, val_loss: 1.3129890211697282 (15 / 35)\n",
            "train_acc: 0.484548825710754, val_acc: 0.5073891625615764, train_loss: 1.186096363220875, val_loss: 1.1667365534552212 (16 / 35)\n",
            "train_acc: 0.49814585908529047, val_acc: 0.39408866995073893, train_loss: 1.153597867680421, val_loss: 1.627859606311239 (17 / 35)\n",
            "train_acc: 0.5203955500618047, val_acc: 0.47783251231527096, train_loss: 1.1213451703487722, val_loss: 1.1975967657977138 (18 / 35)\n",
            "train_acc: 0.522867737948084, val_acc: 0.47783251231527096, train_loss: 1.137606324312566, val_loss: 1.1769562260857944 (19 / 35)\n",
            "train_acc: 0.546353522867738, val_acc: 0.5123152709359606, train_loss: 1.0472092380924485, val_loss: 1.199777027656292 (20 / 35)\n",
            "train_acc: 0.5822002472187886, val_acc: 0.45320197044334976, train_loss: 1.0266858085861017, val_loss: 1.534004875298204 (21 / 35)\n",
            "train_acc: 0.6427688504326329, val_acc: 0.5566502463054187, train_loss: 0.8113290316094869, val_loss: 1.051854182933939 (22 / 35)\n",
            "train_acc: 0.7280593325092707, val_acc: 0.5812807881773399, train_loss: 0.6792279613032771, val_loss: 1.0814191699028015 (23 / 35)\n",
            "train_acc: 0.7404202719406675, val_acc: 0.5615763546798029, train_loss: 0.6242967631083042, val_loss: 1.1547907673079392 (24 / 35)\n",
            "train_acc: 0.7478368355995055, val_acc: 0.6206896551724138, train_loss: 0.6044683791650978, val_loss: 1.1631359622396271 (25 / 35)\n",
            "train_acc: 0.796044499381953, val_acc: 0.625615763546798, train_loss: 0.5315942629453425, val_loss: 1.067136653538408 (26 / 35)\n",
            "train_acc: 0.8022249690976514, val_acc: 0.5665024630541872, train_loss: 0.4996716299627266, val_loss: 1.3682252127548744 (27 / 35)\n",
            "train_acc: 0.823238566131026, val_acc: 0.5911330049261084, train_loss: 0.47180106797530713, val_loss: 1.2254583342321987 (28 / 35)\n",
            "train_acc: 0.8034610630407911, val_acc: 0.5812807881773399, train_loss: 0.4889798306195786, val_loss: 1.3059082123739967 (29 / 35)\n",
            "train_acc: 0.8405438813349815, val_acc: 0.5911330049261084, train_loss: 0.430335882641329, val_loss: 1.3400519777988564 (30 / 35)\n",
            "train_acc: 0.8491965389369592, val_acc: 0.5960591133004927, train_loss: 0.38525785997565215, val_loss: 1.3669714126093635 (31 / 35)\n",
            "train_acc: 0.8689740420271941, val_acc: 0.6305418719211823, train_loss: 0.38302991367020034, val_loss: 1.416145349371022 (32 / 35)\n",
            "train_acc: 0.8813349814585909, val_acc: 0.625615763546798, train_loss: 0.30532311265010326, val_loss: 1.4129076908374656 (33 / 35)\n",
            "train_acc: 0.8899876390605687, val_acc: 0.6206896551724138, train_loss: 0.3097636854213896, val_loss: 1.5287479121109535 (34 / 35)\n",
            "train_acc: 0.896168108776267, val_acc: 0.6009852216748769, train_loss: 0.28594726316713726, val_loss: 1.6063515543937683 (35 / 35)\n",
            "lr 0.005109640841069928, batch 14, decay 0.0005937746882460918, gamma 0.17826825106278887, val accuracy 0.6305418719211823, val loss 1.416145349371022 [12 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.1681087762669963, val_acc: 0.18226600985221675, train_loss: 1.7840599415476155, val_loss: 1.7697211545089195 (1 / 35)\n",
            "train_acc: 0.19777503090234858, val_acc: 0.18226600985221675, train_loss: 1.7651224534208017, val_loss: 1.7492527456706382 (2 / 35)\n",
            "train_acc: 0.21508034610630408, val_acc: 0.29064039408866993, train_loss: 1.7571387226118882, val_loss: 1.7336184121117804 (3 / 35)\n",
            "train_acc: 0.22867737948084055, val_acc: 0.22660098522167488, train_loss: 1.7421930561254286, val_loss: 1.7101416059315497 (4 / 35)\n",
            "train_acc: 0.2694684796044499, val_acc: 0.22167487684729065, train_loss: 1.702896379717201, val_loss: 1.651519917502192 (5 / 35)\n",
            "train_acc: 0.3127317676143387, val_acc: 0.3645320197044335, train_loss: 1.62818651662032, val_loss: 1.503387519878707 (6 / 35)\n",
            "train_acc: 0.3288009888751545, val_acc: 0.4236453201970443, train_loss: 1.578582261784557, val_loss: 1.4942313227160224 (7 / 35)\n",
            "train_acc: 0.3399258343634116, val_acc: 0.31527093596059114, train_loss: 1.5247577337458342, val_loss: 1.5448335259418768 (8 / 35)\n",
            "train_acc: 0.3288009888751545, val_acc: 0.37438423645320196, train_loss: 1.5118039592971613, val_loss: 1.4752149455653036 (9 / 35)\n",
            "train_acc: 0.3980222496909765, val_acc: 0.3694581280788177, train_loss: 1.4178971882508917, val_loss: 1.3498248965869397 (10 / 35)\n",
            "train_acc: 0.38936959208899874, val_acc: 0.3891625615763547, train_loss: 1.428168265501265, val_loss: 1.2987492865529553 (11 / 35)\n",
            "train_acc: 0.38936959208899874, val_acc: 0.43349753694581283, train_loss: 1.4076439994669374, val_loss: 1.2674428958610948 (12 / 35)\n",
            "train_acc: 0.40296662546353523, val_acc: 0.42857142857142855, train_loss: 1.3600188431840008, val_loss: 1.4171057179056366 (13 / 35)\n",
            "train_acc: 0.3943139678615575, val_acc: 0.39408866995073893, train_loss: 1.3664470802720898, val_loss: 1.3158685999550843 (14 / 35)\n",
            "train_acc: 0.41903584672435107, val_acc: 0.39408866995073893, train_loss: 1.3312855102075782, val_loss: 1.3070062630869486 (15 / 35)\n",
            "train_acc: 0.4042027194066749, val_acc: 0.4433497536945813, train_loss: 1.30929146296309, val_loss: 1.2326440041875604 (16 / 35)\n",
            "train_acc: 0.40914709517923364, val_acc: 0.4433497536945813, train_loss: 1.2954354636896084, val_loss: 1.2627336788060042 (17 / 35)\n",
            "train_acc: 0.4276885043263288, val_acc: 0.43842364532019706, train_loss: 1.2969367052480227, val_loss: 1.2297170074115247 (18 / 35)\n",
            "train_acc: 0.4437577255871446, val_acc: 0.43842364532019706, train_loss: 1.2787110084214228, val_loss: 1.1877019675494416 (19 / 35)\n",
            "train_acc: 0.4573547589616811, val_acc: 0.4482758620689655, train_loss: 1.2234154600000795, val_loss: 1.247140158279776 (20 / 35)\n",
            "train_acc: 0.44746600741656367, val_acc: 0.49261083743842365, train_loss: 1.2339057904680815, val_loss: 1.2072289900239466 (21 / 35)\n",
            "train_acc: 0.5364647713226205, val_acc: 0.4729064039408867, train_loss: 1.1399882076255177, val_loss: 1.1522233615367872 (22 / 35)\n",
            "train_acc: 0.49814585908529047, val_acc: 0.46798029556650245, train_loss: 1.150644217050267, val_loss: 1.1676073599918722 (23 / 35)\n",
            "train_acc: 0.5166872682323856, val_acc: 0.4827586206896552, train_loss: 1.0980267411993518, val_loss: 1.138956366795037 (24 / 35)\n",
            "train_acc: 0.5203955500618047, val_acc: 0.5024630541871922, train_loss: 1.061674182656669, val_loss: 1.1523811840658704 (25 / 35)\n",
            "train_acc: 0.5624227441285538, val_acc: 0.5073891625615764, train_loss: 1.0625547726899938, val_loss: 1.1253143093856097 (26 / 35)\n",
            "train_acc: 0.5574783683559951, val_acc: 0.5172413793103449, train_loss: 1.0249667464581644, val_loss: 1.1236802909174577 (27 / 35)\n",
            "train_acc: 0.5673671199011124, val_acc: 0.49261083743842365, train_loss: 1.0308114551790566, val_loss: 1.1008480975193342 (28 / 35)\n",
            "train_acc: 0.5648949320148331, val_acc: 0.5270935960591133, train_loss: 1.0023006950821658, val_loss: 1.0939095134805576 (29 / 35)\n",
            "train_acc: 0.5673671199011124, val_acc: 0.5024630541871922, train_loss: 0.9923268856459996, val_loss: 1.1016444314289562 (30 / 35)\n",
            "train_acc: 0.5896168108776267, val_acc: 0.5270935960591133, train_loss: 0.9860227706258465, val_loss: 1.0980013512038245 (31 / 35)\n",
            "train_acc: 0.5908529048207664, val_acc: 0.5467980295566502, train_loss: 0.9894793977033075, val_loss: 1.0886381547439274 (32 / 35)\n",
            "train_acc: 0.5859085290482077, val_acc: 0.5369458128078818, train_loss: 0.963836417799385, val_loss: 1.0622650603649064 (33 / 35)\n",
            "train_acc: 0.6081582200247219, val_acc: 0.541871921182266, train_loss: 0.9410783004554447, val_loss: 1.0531397432529281 (34 / 35)\n",
            "train_acc: 0.619283065512979, val_acc: 0.5270935960591133, train_loss: 0.9278659163726717, val_loss: 1.0728720494091804 (35 / 35)\n",
            "lr 0.0013885391753410857, batch 11, decay 1.0234302534651643e-05, gamma 0.19729638683881684, val accuracy 0.5467980295566502, val loss 1.0886381547439274 [13 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.17428924598269468, val_acc: 0.21182266009852216, train_loss: 1.78039643732078, val_loss: 1.757135935017628 (1 / 35)\n",
            "train_acc: 0.21631644004944375, val_acc: 0.18719211822660098, train_loss: 1.7529229986652897, val_loss: 1.7375868094965743 (2 / 35)\n",
            "train_acc: 0.24969097651421507, val_acc: 0.33497536945812806, train_loss: 1.707702415245867, val_loss: 1.6273412898256274 (3 / 35)\n",
            "train_acc: 0.29171817058096416, val_acc: 0.33004926108374383, train_loss: 1.6648308414463944, val_loss: 1.6491254714909445 (4 / 35)\n",
            "train_acc: 0.30407911001236093, val_acc: 0.39901477832512317, train_loss: 1.6010693061189687, val_loss: 1.4769656458511728 (5 / 35)\n",
            "train_acc: 0.32756489493201485, val_acc: 0.3103448275862069, train_loss: 1.5632897636799052, val_loss: 1.567420644713153 (6 / 35)\n",
            "train_acc: 0.3584672435105068, val_acc: 0.3842364532019704, train_loss: 1.4960368002300946, val_loss: 1.3871031754416199 (7 / 35)\n",
            "train_acc: 0.39555006180469715, val_acc: 0.35960591133004927, train_loss: 1.436753485641904, val_loss: 1.3921537311206311 (8 / 35)\n",
            "train_acc: 0.3658838071693449, val_acc: 0.3891625615763547, train_loss: 1.470909606541043, val_loss: 1.4375971127026186 (9 / 35)\n",
            "train_acc: 0.380716934487021, val_acc: 0.4088669950738916, train_loss: 1.386450932921821, val_loss: 1.3137768664089917 (10 / 35)\n",
            "train_acc: 0.40173053152039556, val_acc: 0.43349753694581283, train_loss: 1.3689004822331394, val_loss: 1.3012263017334962 (11 / 35)\n",
            "train_acc: 0.40667490729295425, val_acc: 0.42857142857142855, train_loss: 1.3938275506381494, val_loss: 1.2865800196901331 (12 / 35)\n",
            "train_acc: 0.4042027194066749, val_acc: 0.42857142857142855, train_loss: 1.366742755117169, val_loss: 1.3117145126676324 (13 / 35)\n",
            "train_acc: 0.3930778739184178, val_acc: 0.43842364532019706, train_loss: 1.342033024918753, val_loss: 1.2412108315035628 (14 / 35)\n",
            "train_acc: 0.4289245982694685, val_acc: 0.4482758620689655, train_loss: 1.310045230152875, val_loss: 1.2184461217208449 (15 / 35)\n",
            "train_acc: 0.4561186650185414, val_acc: 0.43842364532019706, train_loss: 1.2544079300647024, val_loss: 1.213279895741364 (16 / 35)\n",
            "train_acc: 0.4610630407911001, val_acc: 0.41379310344827586, train_loss: 1.2414020882696097, val_loss: 1.2950321911591027 (17 / 35)\n",
            "train_acc: 0.45982694684796044, val_acc: 0.45320197044334976, train_loss: 1.247909028759993, val_loss: 1.1969098944969365 (18 / 35)\n",
            "train_acc: 0.47713226205191595, val_acc: 0.4482758620689655, train_loss: 1.170304676289906, val_loss: 1.2273060215517806 (19 / 35)\n",
            "train_acc: 0.4969097651421508, val_acc: 0.4236453201970443, train_loss: 1.1553398920372773, val_loss: 1.2924360340011531 (20 / 35)\n",
            "train_acc: 0.484548825710754, val_acc: 0.46798029556650245, train_loss: 1.1625919574860146, val_loss: 1.2184109637889955 (21 / 35)\n",
            "train_acc: 0.5710754017305315, val_acc: 0.5369458128078818, train_loss: 1.027467166316524, val_loss: 1.1216952430790867 (22 / 35)\n",
            "train_acc: 0.5933250927070457, val_acc: 0.5566502463054187, train_loss: 1.0142638446079344, val_loss: 1.0989681198972787 (23 / 35)\n",
            "train_acc: 0.5871446229913473, val_acc: 0.5517241379310345, train_loss: 1.0046421767607312, val_loss: 1.090967190383103 (24 / 35)\n",
            "train_acc: 0.5995055624227441, val_acc: 0.5369458128078818, train_loss: 0.9717621918956488, val_loss: 1.0957471762091069 (25 / 35)\n",
            "train_acc: 0.5982694684796045, val_acc: 0.5320197044334976, train_loss: 0.9699762952784525, val_loss: 1.097665169702962 (26 / 35)\n",
            "train_acc: 0.584672435105068, val_acc: 0.541871921182266, train_loss: 0.9893992272089379, val_loss: 1.0911218861640968 (27 / 35)\n",
            "train_acc: 0.6081582200247219, val_acc: 0.5221674876847291, train_loss: 0.9474723768617374, val_loss: 1.0954438721017885 (28 / 35)\n",
            "train_acc: 0.61557478368356, val_acc: 0.5320197044334976, train_loss: 0.9649574889240807, val_loss: 1.0923698798482642 (29 / 35)\n",
            "train_acc: 0.6106304079110012, val_acc: 0.5270935960591133, train_loss: 0.9371635396268371, val_loss: 1.090869935715727 (30 / 35)\n",
            "train_acc: 0.5995055624227441, val_acc: 0.5172413793103449, train_loss: 0.9297277673950006, val_loss: 1.0962487071605738 (31 / 35)\n",
            "train_acc: 0.6056860321384425, val_acc: 0.5320197044334976, train_loss: 0.9427801590914779, val_loss: 1.0879029418740953 (32 / 35)\n",
            "train_acc: 0.6180469715698393, val_acc: 0.5369458128078818, train_loss: 0.9359011716394695, val_loss: 1.0800885674107839 (33 / 35)\n",
            "train_acc: 0.6093943139678616, val_acc: 0.5172413793103449, train_loss: 0.9320137881672721, val_loss: 1.0835999480902856 (34 / 35)\n",
            "train_acc: 0.6341161928306551, val_acc: 0.5270935960591133, train_loss: 0.9231168619266105, val_loss: 1.08390245017747 (35 / 35)\n",
            "lr 0.002012613859565053, batch 11, decay 7.395805296094665e-06, gamma 0.022057312149965858, val accuracy 0.5566502463054187, val loss 1.0989681198972787 [14 / 50]\n",
            "-------------------------------------\n",
            "train_acc: 0.1903584672435105, val_acc: 0.18226600985221675, train_loss: 1.7757940566436616, val_loss: 1.759127798338829 (1 / 35)\n",
            "train_acc: 0.24103831891223734, val_acc: 0.22660098522167488, train_loss: 1.7458158996697557, val_loss: 1.716014188498699 (2 / 35)\n",
            "train_acc: 0.2904820766378245, val_acc: 0.33004926108374383, train_loss: 1.7008389993415334, val_loss: 1.6158697182321784 (3 / 35)\n",
            "train_acc: 0.311495673671199, val_acc: 0.2512315270935961, train_loss: 1.6408852494986008, val_loss: 1.6048823618536512 (4 / 35)\n",
            "train_acc: 0.3053152039555006, val_acc: 0.4088669950738916, train_loss: 1.6273595834397268, val_loss: 1.4909534695113233 (5 / 35)\n",
            "train_acc: 0.35599505562422745, val_acc: 0.3842364532019704, train_loss: 1.5236040987396713, val_loss: 1.4348232414334865 (6 / 35)\n",
            "train_acc: 0.4004944375772559, val_acc: 0.3842364532019704, train_loss: 1.4712052398323276, val_loss: 1.3832161042637425 (7 / 35)\n",
            "train_acc: 0.3621755253399258, val_acc: 0.3694581280788177, train_loss: 1.461655443766798, val_loss: 1.4095436537207053 (8 / 35)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qxj7-SlSKb_3"
      },
      "source": [
        "**Grid search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aPmSObkPKbu3",
        "outputId": "4ee4e2f6-7038-49db-9ba6-667755ca46e8",
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        }
      },
      "source": [
        "NUM_CLASSES = 6\n",
        "DEVICE = 'cuda'\n",
        "#BATCH_SIZE = 16\n",
        "#LR = 0.001\n",
        "MOMENTUM = 0.9\n",
        "#WEIGHT_DECAY = 5e-5\n",
        "NUM_EPOCHS = 100\n",
        "STEP_SIZE = 60\n",
        "#GAMMA = 0.1\n",
        "\n",
        "lr_range = [0.005, 0.001, 0.0005]\n",
        "batch_size_range = [16, 8]\n",
        "weight_decay_range = [5e-5, 5e-3]\n",
        "gamma_range = [0.1, 0.01]\n",
        "hyperparameters_sets = []\n",
        "\n",
        "for lr in lr_range:\n",
        "  for batch_size in batch_size_range:\n",
        "    for weight_decay in weight_decay_range:\n",
        "      for gamma in gamma_range:\n",
        "        hyperparameters_sets.append({'lr': lr, 'batch_size': batch_size, 'weight_decay': weight_decay, 'gamma': gamma})\n",
        "\n",
        "for set in hyperparameters_sets:\n",
        "  print(set)\n",
        "\n",
        "\n",
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-224'\n",
        "compose=[#transforms.Resize(224),\n",
        "         transforms.CenterCrop(224),\n",
        "         transforms.RandomGrayscale(),\n",
        "         transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
        "         transforms.ToTensor()\n",
        "         ]\n",
        "train_dataset, val_dataset = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, compose)\n",
        "\n",
        "train_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]\n",
        "val_indexes = [idx for idx in range(len(train_dataset)) if not idx % 5]\n",
        "val_dataset = Subset(val_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "print('training set {}'.format(len(train_dataset)))\n",
        "print('validation set {}'.format(len(val_dataset)))\n",
        "\n",
        "best_net = vgg11()\n",
        "best_net = best_net.to(DEVICE)\n",
        "best_net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "best_set = {}\n",
        "best_accuracy = 0.0\n",
        "best_loss = 0.0\n",
        "val_accuracies = []\n",
        "val_losses = []\n",
        "\n",
        "for set in hyperparameters_sets:\n",
        "\n",
        "  net = vgg11()\n",
        "  net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "  current_net, val_accuracy, val_loss = train_network(net, net.parameters(), set['lr'], NUM_EPOCHS, set['batch_size'], set['weight_decay'], STEP_SIZE, set['gamma'], train_dataset, val_dataset=val_dataset)\n",
        "  val_accuracies.append(val_accuracy)\n",
        "  val_losses.append(val_loss)\n",
        "\n",
        "  if val_accuracy > best_accuracy:\n",
        "    best_accuracy = val_accuracy\n",
        "    best_loss = val_loss\n",
        "    best_net = copy.deepcopy(current_net)\n",
        "    best_set = copy.deepcopy(set)\n",
        "  \n",
        "  print(\"({}), val accuracy {}, val loss {}\".format(set, val_accuracy, val_loss))\n",
        "\n",
        "print(\"\\n\\n({}), best val accuracy {}, best val loss {}\\n\".format(best_set, best_accuracy, best_loss))\n",
        "print(\"\\nval_accuracies\")\n",
        "print(val_accuracies)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "{'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "{'lr': 0.001, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.001, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "{'lr': 0.001, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.001, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.001, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.001, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.0005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}\n",
            "{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.01}\n",
            "{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}\n",
            "{'lr': 0.0005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.01}\n",
            "Cloning into 'AIML_project'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 24392 (delta 10), reused 13 (delta 5), pack-reused 24373\u001b[K\n",
            "Receiving objects: 100% (24392/24392), 2.15 GiB | 47.69 MiB/s, done.\n",
            "Resolving deltas: 100% (71/71), done.\n",
            "Checking out files: 100% (24636/24636), done.\n",
            "training set 809\n",
            "validation set 203\n",
            "({'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.4876847290640394, val loss 1.3147739389259827\n",
            "({'lr': 0.005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.01}), val accuracy 0.6059113300492611, val loss 1.5047687838230226\n",
            "({'lr': 0.005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}), val accuracy 0.3448275862068966, val loss 1.6433078479297056\n",
            "({'lr': 0.005, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.01}), val accuracy 0.5812807881773399, val loss 2.414570222347241\n",
            "({'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.2955665024630542, val loss 1.7655747535780733\n",
            "({'lr': 0.005, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.01}), val accuracy 0.4876847290640394, val loss 1.3504160378366856\n",
            "({'lr': 0.005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}), val accuracy 0.18226600985221675, val loss 1.7624990276515191\n",
            "({'lr': 0.005, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.01}), val accuracy 0.270935960591133, val loss 1.7162450311219164\n",
            "({'lr': 0.001, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.6108374384236454, val loss 2.431815377597151\n",
            "({'lr': 0.001, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.01}), val accuracy 0.6551724137931034, val loss 1.9367152525873608\n",
            "({'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.1}), val accuracy 0.6403940886699507, val loss 1.528708166676789\n",
            "({'lr': 0.001, 'batch_size': 16, 'weight_decay': 0.005, 'gamma': 0.01}), val accuracy 0.6600985221674877, val loss 1.645547920847174\n",
            "({'lr': 0.001, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.7536945812807881, val loss 1.4387520968620413\n",
            "({'lr': 0.001, 'batch_size': 8, 'weight_decay': 5e-05, 'gamma': 0.01}), val accuracy 0.6995073891625616, val loss 2.476622701278461\n",
            "({'lr': 0.001, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.1}), val accuracy 0.6650246305418719, val loss 3.20528265466831\n",
            "({'lr': 0.001, 'batch_size': 8, 'weight_decay': 0.005, 'gamma': 0.01}), val accuracy 0.6305418719211823, val loss 1.9122127376753708\n",
            "({'lr': 0.0005, 'batch_size': 16, 'weight_decay': 5e-05, 'gamma': 0.1}), val accuracy 0.6502463054187192, val loss 1.084208725121221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S1laZWm8Q0tm"
      },
      "source": [
        "**Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TKl555WRQ1AF",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "# todo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jJGI06ylKePa"
      },
      "source": [
        "**Mean / std computation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YDJptx12L1OL",
        "trusted": false,
        "outputId": "3faa7a3e-7dce-418a-8a16-5ac13471f165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "TRAIN_DATA_DIR = 'AIML_project/ravdess-emotional-song-spec-672'\n",
        "pixel_mean = np.zeros(3)\n",
        "pixel_std = np.zeros(3)\n",
        "k = 1\n",
        "dataset, _ = get_datasets(TRAIN_DATA_DIR, TRAIN_DATA_DIR, [])\n",
        "for image, _ in tqdm(dataset, \"Computing mean/std\", len(dataset), unit=\"samples\"):\n",
        "    image = np.array(image)\n",
        "    pixels = image.reshape((-1, image.shape[2]))\n",
        "\n",
        "    for pixel in pixels:\n",
        "        diff = pixel - pixel_mean\n",
        "        pixel_mean += diff / k\n",
        "        pixel_std += diff * (pixel - pixel_mean)\n",
        "        k += 1\n",
        "\n",
        "pixel_std = np.sqrt(pixel_std / (k - 2))\n",
        "print(pixel_mean)\n",
        "print(pixel_std)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'AIML_project'...\n",
            "remote: Enumerating objects: 48, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 24421 (delta 28), reused 33 (delta 14), pack-reused 24373\u001b[K\n",
            "Receiving objects: 100% (24421/24421), 2.15 GiB | 48.26 MiB/s, done.\n",
            "Resolving deltas: 100% (89/89), done.\n",
            "Checking out files: 100% (24638/24638), done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Computing mean/std: 100%|| 1012/1012 [47:31<00:00,  2.82s/samples]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[45.6068733   0.81077038 57.85301916]\n",
            "[66.92374056  9.88349788 49.96761776]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}